{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimus\n",
    "\n",
    "## Pandas and Optimus side by side\n",
    "\n",
    "From the web:\n",
    "\n",
    "Pandas is a Python package providing fast, flexible, and expressive data structures designed to make working with “relational” or “labeled” data both easy and intuitive. \n",
    "\n",
    "Here is list of the 90th percentil functions used in pandas. Thanks to Devin Petersohn. https://rise.cs.berkeley.edu/blog/pandas-on-ray-early-lessons/\n",
    "\n",
    "|Pandas|Optimus\n",
    "|---|---|---|\n",
    "|pd.read_csv()|op.read.csv()|\n",
    "|pd.Dataframe|op.create.df()|\n",
    "|df.append|df.row().append()|\n",
    "|df.mean|df.cols().mean()|\n",
    "|df.head()|df.head()|\n",
    "|df.drop()|df.cols().drop()\n",
    "|df.sum()|df.cols().sum()||\n",
    "|df.to_csv()|df.save().csv()|\n",
    "|df.get()|NI|\n",
    "|df.mode()|df.cols().mode()|\n",
    "|df.astype()|df.cols().cast(),  astype() as alias|\n",
    "|df.sub()|NI|\n",
    "|pd.concat()|optimus.concat()|\n",
    "|df.apply|df.cols().apply()|\n",
    "|df.groupby()|df.groupby()|\n",
    "|df.join()|df.join()|\n",
    "|df.fillna()|df.fillna()|\n",
    "|df.max()|df.cols().max()|\n",
    "|reset_index|NA|\n",
    "\n",
    "NI= Not implemented\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimus\n",
    "\n",
    "## Pandas, Optimus and Spark side by side\n",
    "\n",
    "|Pandas|Optimus|Spark|\n",
    "|---|---|---|\n",
    "|pd.read_csv()|op.read.csv()|spark.read.csv()|\n",
    "|pd.Dataframe|op.create.df()|df.createdataframe()|\n",
    "|pd.append|df.row().append()|df.union()|\n",
    "|pd.mean|df.cols().mean()|done via agg|\n",
    "|df.head()|df.head()|df.show()|\n",
    "|df.drop()|df.cols().drop()|df.drop()|\n",
    "|df.sum()|df.cols().sum()|done via agg function|\n",
    "|df.to_csv()|df.save().csv()|df.read.csv()|\n",
    "|df.get()|NI|NI|\n",
    "|df.mode()|df.cols().mode()|done via agg function|\n",
    "|df.astype()|df.cols().cast(),  astype() as alias|df.cast()|\n",
    "|df.sub()|NI|NI|\n",
    "|pd.concat()|optimus.concat()|NI|\n",
    "|df.apply|df.cols().apply()|NI|\t\t\t\n",
    "|df.groupby()|via Spark DataFrame|df.groupby()|\n",
    "|df.join()|via Spark DataFrame|df.join()|\n",
    "|df.fillna()|via Spark DataFrame|df.fillna()|\n",
    "|df.max()|df.cols().max()|done via agg function|\n",
    "|reset_index|NA|NA|\n",
    "\n",
    "NI= Not implemented\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimus import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "             ____        __  _                     \n",
      "            / __ \\____  / /_(_)___ ___  __  _______\n",
      "           / / / / __ \\/ __/ / __ `__ \\/ / / / ___/\n",
      "          / /_/ / /_/ / /_/ / / / / / / /_/ (__  ) \n",
      "          \\____/ .___/\\__/_/_/ /_/ /_/\\__,_/____/  \n",
      "              /_/                                  \n",
      "              \n",
      "Just checking that all necessary environments vars are present...\n",
      "-----\n",
      "PYSPARK_PYTHON=python\n",
      "SPARK_HOME=C:\\opt\\spark\\spark-2.3.1-bin-hadoop2.7\n",
      "JAVA_HOME=C:\\java8\n",
      "-----\n",
      "Starting or getting SparkSession and SparkContext...\n",
      "Setting checkpoint folder ( local ). If you are in a cluster initialize optimus with master='your_ip' as param\n",
      "Deleting previous folder if exists...\n",
      "Creating the checkpoint directory...\n",
      "Optimus successfully imported. Have fun :).\n"
     ]
    }
   ],
   "source": [
    "# Create optimus\n",
    "op = Optimus(master=\"local\", app_name= \"optimus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-EP49A8K8:4045\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>optimus</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x19d121fae48>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.get_ss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-EP49A8K8:4045\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>optimus</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=optimus>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.get_sc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe\n",
    "### Spark\n",
    "\n",
    "This is ugly:\n",
    "\n",
    "```\n",
    "val someData = Seq(\n",
    "  Row(8, \"bat\"),\n",
    "  Row(64, \"mouse\"),\n",
    "  Row(-27, \"horse\")\n",
    ")\n",
    "\n",
    "val someSchema = List(\n",
    "  StructField(\"number\", IntegerType, true),\n",
    "  StructField(\"word\", StringType, true)\n",
    ")\n",
    "\n",
    "val someDF = spark.createDataFrame(\n",
    "  spark.sparkContext.parallelize(someData),\n",
    "  StructType(someSchema)\n",
    ")```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+----------+-------------+------+-----+--------+-----+\n",
      "|              words|num|animals|     thing|  two strings|filter|num 2|    date|num 3|\n",
      "+-------------------+---+-------+----------+-------------+------+-----+--------+-----+\n",
      "|  I like     fish  |  1|    dog|&^%$#housé|      cat-car|     a|    1|20150510|    3|\n",
      "|            zombies|  2|    cat|        tv|       dog-tv|     b|    2|20160510|    3|\n",
      "|simpsons   cat lady|  2|   frog|     table|eagle-tv-plus|     1|    3|20170510|    4|\n",
      "|               null|  3|  eagle|     glass|      lion-pc|     c|    4|20180510|    5|\n",
      "+-------------------+---+-------+----------+-------------+------+-----+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, BooleanType, IntegerType, ArrayType\n",
    "\n",
    "df = op.create.df(\n",
    "    [\n",
    "                (\"words\", \"str\", True),\n",
    "                (\"num\", \"int\", True),\n",
    "                (\"animals\", \"str\", True),\n",
    "                (\"thing\", StringType(), True),\n",
    "                (\"two strings\", StringType(), True),\n",
    "                (\"filter\", StringType(), True),\n",
    "                (\"num 2\", \"string\", True),\n",
    "                (\"date\", \"string\", True),\n",
    "                (\"num 3\", \"string\", True)\n",
    "                \n",
    "            ],[\n",
    "                (\"  I like     fish  \", 1, \"dog\", \"&^%$#housé\", \"cat-car\", \"a\",\"1\", \"20150510\", \"3\"),\n",
    "                (\"    zombies\", 2, \"cat\", \"tv\", \"dog-tv\", \"b\",\"2\", \"20160510\", \"3\"),\n",
    "                (\"simpsons   cat lady\", 2, \"frog\", \"table\",\"eagle-tv-plus\",\"1\",\"3\", \"20170510\", \"4\"),\n",
    "                (None, 3, \"eagle\", \"glass\", \"lion-pc\", \"c\",\"4\", \"20180510\", \"5\"),\n",
    "    \n",
    "            ]\n",
    "            )\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concat\n",
    "### Spark\n",
    "No available in Spark Vanilla\n",
    "\n",
    "### Pandas\n",
    "Almost the same functionlity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+----------+-------------+------+-----+--------+-----+\n",
      "|              words|num|animals|     thing|  two strings|filter|num 2|    date|num 3|\n",
      "+-------------------+---+-------+----------+-------------+------+-----+--------+-----+\n",
      "|  I like     fish  |  1|    dog|&^%$#housé|      cat-car|     a|    1|20150510|    3|\n",
      "|            zombies|  2|    cat|        tv|       dog-tv|     b|    2|20160510|    3|\n",
      "|simpsons   cat lady|  2|   frog|     table|eagle-tv-plus|     1|    3|20170510|    4|\n",
      "|               null|  3|  eagle|     glass|      lion-pc|     c|    4|20180510|    5|\n",
      "|  I like     fish  |  1|    dog|&^%$#housé|      cat-car|     a|    1|20150510|    3|\n",
      "|            zombies|  2|    cat|        tv|       dog-tv|     b|    2|20160510|    3|\n",
      "|simpsons   cat lady|  2|   frog|     table|eagle-tv-plus|     1|    3|20170510|    4|\n",
      "|               null|  3|  eagle|     glass|      lion-pc|     c|    4|20180510|    5|\n",
      "+-------------------+---+-------+----------+-------------+------+-----+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "op.concat(df,df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
