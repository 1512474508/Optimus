{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--jars mongo-hadoop-spark.jar --driver-class-path mongo-hadoop-spark.jar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just checking that all necessary environment vars are present...\n",
      "PYSPARK_PYTHON=python\n",
      "SPARK_HOME=C:\\opt\\spark\\spark-2.3.1-bin-hadoop2.7\n",
      "JAVA_HOME=C:\\java8\n",
      "-----\n",
      "Starting or getting SparkSession and SparkContext...\n",
      "Setting checkpoint folder (local). If you are in a cluster change it with set_check_point_ folder(path,'hadoop').\n",
      "Deleting previous folder if exists...\n",
      "Creation of checkpoint directory...\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ironmussa/Optimus\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ironmussa/Optimus/raw/master/images/robotOptimus.png\" style=\"float:left;margin-right:10px;vertical-align:top;text-align:center\" height=\"50\" width=\"50\"/>\n",
       "            </a>\n",
       "            <span><b><h2>Optimus successfully imported. Have fun :).</h2></b></span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import optimus as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+-----+\n",
      "|              words|num|animals|thing|\n",
      "+-------------------+---+-------+-----+\n",
      "|  I like     fish  |  1|    dog|housé|\n",
      "|            zombies|  2|    cat|   tv|\n",
      "|simpsons   cat lady|  2|   frog|table|\n",
      "|               null|  3|  eagle|glass|\n",
      "+-------------------+---+-------+-----+\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "normalize() argument 2 must be str, not Column",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1e1abd5b2103>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m             ])\n\u001b[0;32m     15\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"words\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"words\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"words\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"words\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove_accents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"words\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Optimus\\optimus\\optimus.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Optimus\\optimus\\optimus.py\u001b[0m in \u001b[0;36mremove_accents\u001b[1;34m(self, columns)\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \"\"\"\n\u001b[1;32m--> 446\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_to_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_remove_accents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Optimus\\optimus\\optimus.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Optimus\\optimus\\optimus.py\u001b[0m in \u001b[0;36mapply_to_row\u001b[1;34m(self, columns, func)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[0mself\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Optimus\\optimus\\optimus.py\u001b[0m in \u001b[0;36m_remove_accents\u001b[1;34m(input_str)\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[1;31m# first, normalize strings:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m     \u001b[0mnfkd_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0municodedata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'NFKD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[1;31m# Keep chars that has no other char combined (i.e. accents chars)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: normalize() argument 2 must be str, not Column"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, BooleanType, IntegerType, ArrayType\n",
    "\n",
    "df = op.create_df([\n",
    "                (\"  I like     fish  \", 1, \"dog\", \"housé\" ),\n",
    "                (\"    zombies\", 2, \"cat\", \"tv\"),\n",
    "                (\"simpsons   cat lady\", 2, \"frog\", \"table\"),\n",
    "                (None, 3, \"eagle\", \"glass\")\n",
    "            ],\n",
    "            [\n",
    "                (\"words\", StringType(), True),\n",
    "                (\"num\", IntegerType(), True),\n",
    "                (\"animals\", StringType(), True),\n",
    "                (\"thing\", StringType(), True)\n",
    "            ])\n",
    "df.show()\n",
    "df = df.upper(\"words\").lower(\"words\").reverse(\"words\").trim(\"words\").remove_accents(\"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['words', 'num', 'animals', 'thing']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[words: string, num: int, animals: string, thing: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.astype([(\"num\",\"string\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[num: string, words: string, animals: string, thing: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[words: string, animals: string, thing: string, num: string]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.move_col(\"num\", \"thing\", \"after\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+-----+\n",
      "|              words|num|animals|thing|\n",
      "+-------------------+---+-------+-----+\n",
      "|  I like     fish  |  1|    dog|housé|\n",
      "|            zombies|  2|    cat|   tv|\n",
      "|simpsons   cat lady|  2|   frog|table|\n",
      "|               null|  3|  eagle|glass|\n",
      "+-------------------+---+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[words: string, num: int, animals: string, thing: string]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tup = [(\"num\",\"int\")]\n",
    "\n",
    "columns = []\n",
    "new_col = \"\"\n",
    "for c in df.columns:\n",
    "    for t in tup:\n",
    "        if t[0] == c:\n",
    "            new_col = col(c).cast(DICT_TYPES[TYPES[t[1]]]).alias(c)\n",
    "        else:\n",
    "            new_col = col(c)\n",
    "    columns.append(new_col)\n",
    "\n",
    "#print(DICT_TYPES[TYPES[\"string\"]])\n",
    "df =df.select(columns)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[words: string, num: int, animals: string, thing: string]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Column<b'CAST(num AS INT) AS `num`'>, Column<b'words'>, Column<b'animals'>, Column<b'thing'>]\n",
      "+-------------------+---+-------+-----+\n",
      "|              words|num|animals|thing|\n",
      "+-------------------+---+-------+-----+\n",
      "|  I like     fish  |  1|    dog|housé|\n",
      "|            zombies|  2|    cat|   tv|\n",
      "|simpsons   cat lady|  2|   frog|table|\n",
      "|               null|  3|  eagle|glass|\n",
      "+-------------------+---+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, DoubleType\n",
    "\n",
    "# You can use string, str or String as param\n",
    "TYPES = {'string': 'string', 'str': 'string', 'String': 'string', 'integer': 'int',\n",
    "         'int': 'int', 'float': 'float', 'double': 'double', 'Double': 'double'}\n",
    "\n",
    "# Instead StringType() just use string\n",
    "DICT_TYPES = {'string': StringType(), 'int': IntegerType(), 'float': FloatType(), 'double': DoubleType()}\n",
    "\n",
    "\n",
    "\n",
    "def a(self, cols_and_types):\n",
    "    \"\"\"\n",
    "\n",
    "    :param self:\n",
    "    :param cols_and_types:\n",
    "            List of tuples of column names and types to be casted. This variable should have the\n",
    "            following structure:\n",
    "\n",
    "            colsAndTypes = [('columnName1', 'integer'), ('columnName2', 'float'), ('columnName3', 'string')]\n",
    "\n",
    "            The first parameter in each tuple is the column name, the second is the final datatype of column after\n",
    "            the transformation is made.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if columnNames to be process are in dataframe\n",
    "    column_names = self._parse_columns(cols_and_types, 0)\n",
    "\n",
    "    not_specified_columns = filter(lambda c: c not in column_names, self.columns)\n",
    "\n",
    "    exprs = [col(column[0]).cast(DICT_TYPES[TYPES[column[1]]]).alias(column[0]) for column in cols_and_types] + [\n",
    "        col(column) for column in not_specified_columns]\n",
    "    \n",
    "    \n",
    "    for \n",
    "    print(exprs)\n",
    "    #return self.select(*exprs)\n",
    "\n",
    "df.a = a\n",
    "\n",
    "df.a(df, [(\"num\",\"int\")])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-----+\n",
      "|              words|num|thing|\n",
      "+-------------------+---+-----+\n",
      "|  I like     fish  |  1|housé|\n",
      "|            zombies|  2|   tv|\n",
      "|simpsons   cat lady|  2|table|\n",
      "|               null|  3|glass|\n",
      "+-------------------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_(\"animals\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ([(\"num\", \"numbers\")])\n",
    "for c in columns: \n",
    "    assert isinstance(c, tuple)\n",
    "    \n",
    "df = df.rename(columns)    \n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1]\n",
      "3\n",
      "[2]\n",
      "2.0\n",
      "0.816496580927726\n",
      "-1.0000000000000002\n",
      "2.0\n",
      "0.0\n",
      "0.0\n",
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(df.min([\"numbers\", \"numbers\"]))\n",
    "print(df.max(\"numbers\"))\n",
    "print(df.range(\"numbers\"))\n",
    "print(df.median(\"numbers\"))\n",
    "print(df.stddev(\"numbers\"))\n",
    "print(df.kurt(\"numbers\"))\n",
    "print(df.mean(\"numbers\"))\n",
    "print(df.skewness(\"numbers\"))\n",
    "print(df.sum(\"numbers\"))\n",
    "print(df.variance(\"numbers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = op.get_spark()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+---+\n",
      "|   abc|def|ghi|\n",
      "+------+---+---+\n",
      "|[1, 2]|  2|  3|\n",
      "+------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "j = {'abc':{\"a\":1, \"b\":2}, 'def':2, 'ghi':3}\n",
    "a=[json.dumps(j)]\n",
    "jsonRDD = sc.parallelize(a)\n",
    "\n",
    "df = spark.read.json(jsonRDD)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|myCol|\n",
      "+-----+\n",
      "|    0|\n",
      "|    1|\n",
      "|    2|\n",
      "|   20|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "firstDF = spark.range(3).toDF(\"myCol\")\n",
    "newRow = spark.createDataFrame([[20]])\n",
    "appended = firstDF.union(newRow)\n",
    "appended.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1a6ce2362cd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+-----+\n",
      "|              words|num|animals|thing|\n",
      "+-------------------+---+-------+-----+\n",
      "|  I like     fish  |  1|    dog|housé|\n",
      "|            zombies|  2|    cat|   tv|\n",
      "|simpsons   cat lady|  2|   frog|table|\n",
      "|               null|  3|  eagle|glass|\n",
      "+-------------------+---+-------+-----+\n",
      "\n",
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mixed type replacements are not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-090c0157bd37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mnewsdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"num\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"words\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"4\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-090c0157bd37>\u001b[0m in \u001b[0;36mreplace\u001b[1;34m(df, columns, to_replace, value)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mto_replace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mnewsdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_replace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;31m#newsdf = df.withColumn(column, when(df[column] == r, value).otherwise(0))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mnewsdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mreplace\u001b[1;34m(self, to_replace, value, subset)\u001b[0m\n\u001b[0;32m   1664\u001b[0m                    \u001b[1;32mand\u001b[0m \u001b[0mall_of_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrep_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1665\u001b[0m                    for all_of_type in [all_of_bool, all_of_str, all_of_numeric]):\n\u001b[1;32m-> 1666\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mixed type replacements are not supported\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1667\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msubset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Mixed type replacements are not supported"
     ]
    }
   ],
   "source": [
    "df\n",
    "df.show()\n",
    "from pyspark.sql.functions import when  \n",
    "\n",
    "def replace(df, columns, to_replace, value):\n",
    "    for r in to_replace:\n",
    "        print(r)\n",
    "        newsdf = df.replace(to_replace, value, columns)\n",
    "        #newsdf = df.withColumn(column, when(df[column] == r, value).otherwise(0))\n",
    "    newsdf.show()\n",
    "        \n",
    "replace(df,[\"num\",\"words\"], [0, 1, 2, 3], \"4\")    \n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-------+-----+\n",
      "|words|num|animals|thing|\n",
      "+-----+---+-------+-----+\n",
      "| null|  3|  eagle|glass|\n",
      "+-----+---+-------+-----+\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Column' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-300d3e679631>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'3'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'Column' object is not callable"
     ]
    }
   ],
   "source": [
    "a = df[df.num == '3']\n",
    "a.show()\n",
    "df[1].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
