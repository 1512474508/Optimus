{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All this cell must be run to executed the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimus import Optimus\n",
    "from optimus.helpers.test import Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = Optimus(master='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    .data_type {\n",
       "        font-size: 0.8em;\n",
       "        font-weight: normal;\n",
       "    }\n",
       "\n",
       "    .column_name {\n",
       "        font-size: 1.2em;\n",
       "    }\n",
       "\n",
       "    .info_items {\n",
       "        margin: 10px 0;\n",
       "        font-size: 0.8em;\n",
       "    }\n",
       "\n",
       "    .optimus_table td {\n",
       "        padding: 2px;\n",
       "        border-left: 1px solid #cccccc;\n",
       "        border-right: 1px solid #cccccc;\n",
       "    }\n",
       "\n",
       "    .optimus_table tr:nth-child(even) {\n",
       "        background-color: #f2f2f2 !important;\n",
       "    }\n",
       "\n",
       "    .optimus_table tr:nth-child(odd) {\n",
       "        background-color: #ffffff !important;\n",
       "    }\n",
       "\n",
       "    .optimus_table thead {\n",
       "        border-bottom: 1px solid black;\n",
       "    }\n",
       "    .optimus_table{\n",
       "        font-size: 12px;\n",
       "    }\n",
       "\n",
       "    .optimus_table tbody{\n",
       "        font-family: monospace;\n",
       "        border-bottom: 1px solid #cccccc;\n",
       "    }\n",
       "\n",
       "\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<div class=\"info_items\">Viewing 6 of 6 rows / 16 columns</div>\n",
       "<div class=\"info_items\">8 partition(s)</div>\n",
       "\n",
       "<table class=\"optimus_table\">\n",
       "    <thead>\n",
       "    <tr>\n",
       "        \n",
       "        <th>\n",
       "            <div class=\"column_name\">names</div>\n",
       "            <div class=\"data_type\">1 (string)</div>\n",
       "            <div class=\"data_type\">\n",
       "                \n",
       "                nullable\n",
       "                \n",
       "            </div>\n",
       "        </th>\n",
       "        \n",
       "        <th>\n",
       "            <div class=\"column_name\">height(ft)</div>\n",
       "            <div class=\"data_type\">2 (smallint)</div>\n",
       "            <div class=\"data_type\">\n",
       "                \n",
       "                nullable\n",
       "                \n",
       "            </div>\n",
       "        </th>\n",
       "        \n",
       "        <th>\n",
       "            <div class=\"column_name\">function</div>\n",
       "            <div class=\"data_type\">3 (string)</div>\n",
       "            <div class=\"data_type\">\n",
       "                \n",
       "                nullable\n",
       "                \n",
       "            </div>\n",
       "        </th>\n",
       "        \n",
       "        <th>\n",
       "            <div class=\"column_name\">rank</div>\n",
       "            <div class=\"data_type\">4 (tinyint)</div>\n",
       "            <div class=\"data_type\">\n",
       "                \n",
       "                nullable\n",
       "                \n",
       "            </div>\n",
       "        </th>\n",
       "        \n",
       "        <th>\n",
       "            <div class=\"column_name\">age</div>\n",
       "            <div class=\"data_type\">5 (int)</div>\n",
       "            <div class=\"data_type\">\n",
       "                \n",
       "                nullable\n",
       "                \n",
       "            </div>\n",
       "        </th>\n",
       "        \n",
       "        <th>\n",
       "            <div class=\"column_name\">weight(t)</div>\n",
       "            <div class=\"data_type\">6 (float)</div>\n",
       "            <div class=\"data_type\">\n",
       "                \n",
       "                nullable\n",
       "                \n",
       "            </div>\n",
       "        </th>\n",
       "        \n",
       "        <th>\n",
       "            <div class=\"column_name\">japanese name</div>\n",
       "            <div class=\"data_type\">7 (array&lt;string&gt;)</div>\n",
       "            <div class=\"data_type\">\n",
       "                \n",
       "                nullable\n",
       "                \n",
       "            </div>\n",
       "        </th>\n",
       "        \n",
       "        <th>\n",
       "            <div class=\"column_name\">last position seen</div>\n",
       "            <div class=\"data_type\">8 (string)</div>\n",
       "            <div class=\"data_type\">\n",
       "                \n",
       "                nullable\n",
       "                \n",
       "            </div>\n",
       "        </th>\n",
       "        \n",
       "        <th>\n",
       "            <div class=\"column_name\">date arrival</div>\n",
       "            <div class=\"data_type\">9 (string)</div>\n",
       "            <div class=\"data_type\">\n",
       "                \n",
       "                nullable\n",
       "                \n",
       "            </div>\n",
       "        </th>\n",
       "        \n",
       "        <th>\n",
       "            <div class=\"column_name\">last date seen</div>\n",
       "            <div class=\"data_type\">10 (string)</div>\n",
       "            <div class=\"data_type\">\n",
       "                \n",
       "                nullable\n",
       "                \n",
       "            </div>\n",
       "        </th>\n",
       "        \n",
       "        <th>\n",
       "            <div class=\"column_name\">attributes</div>\n",
       "            <div class=\"data_type\">11 (array&lt;float&gt;)</div>\n",
       "            <div class=\"data_type\">\n",
       "                \n",
       "                nullable\n",
       "                \n",
       "            </div>\n",
       "        </th>\n",
       "        \n",
       "        <th>\n",
       "            <div class=\"column_name\">Date Type</div>\n",
       "            <div class=\"data_type\">12 (date)</div>\n",
       "            <div class=\"data_type\">\n",
       "                \n",
       "                nullable\n",
       "                \n",
       "            </div>\n",
       "        </th>\n",
       "        \n",
       "        <th>\n",
       "            <div class=\"column_name\">Tiemstamp</div>\n",
       "            <div class=\"data_type\">13 (timestamp)</div>\n",
       "            <div class=\"data_type\">\n",
       "                \n",
       "                nullable\n",
       "                \n",
       "            </div>\n",
       "        </th>\n",
       "        \n",
       "        <th>\n",
       "            <div class=\"column_name\">Cybertronian</div>\n",
       "            <div class=\"data_type\">14 (boolean)</div>\n",
       "            <div class=\"data_type\">\n",
       "                \n",
       "                nullable\n",
       "                \n",
       "            </div>\n",
       "        </th>\n",
       "        \n",
       "        <th>\n",
       "            <div class=\"column_name\">function(binary)</div>\n",
       "            <div class=\"data_type\">15 (binary)</div>\n",
       "            <div class=\"data_type\">\n",
       "                \n",
       "                nullable\n",
       "                \n",
       "            </div>\n",
       "        </th>\n",
       "        \n",
       "        <th>\n",
       "            <div class=\"column_name\">NullType</div>\n",
       "            <div class=\"data_type\">16 (null)</div>\n",
       "            <div class=\"data_type\">\n",
       "                \n",
       "                nullable\n",
       "                \n",
       "            </div>\n",
       "        </th>\n",
       "        \n",
       "    </tr>\n",
       "\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "    <tr>\n",
       "        \n",
       "        <td>\n",
       "            <div title='Optim&#39;us'>Optim&#39;us</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='28'>28</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='Leader'>Leader</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='10'>10</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='5000000'>5000000</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='4.300000190734863'>4.300000190734863</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='[&#39;Inochi&#39;,⸱&#39;Convoy&#39;]'>[&#39;Inochi&#39;,⸱&#39;Convoy&#39;]</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='19.442735,-99.201111'>19.442735,-99.201111</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='1980/04/10'>1980/04/10</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='2016/09/10'>2016/09/10</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='[8.53439998626709,⸱4300.0]'>[8.53439998626709,⸱4300.0]</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='2016-09-10'>2016-09-10</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='2014-06-24⸱00:00:00'>2014-06-24⸱00:00:00</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='True'>True</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='bytearray(b&#39;Leader&#39;)'>bytearray(b&#39;Leader&#39;)</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='None'>None</div>\n",
       "        </td>\n",
       "        \n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        \n",
       "        <td>\n",
       "            <div title='bumbl#ebéé⸱⸱'>bumbl#ebéé⸱⸱</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='17'>17</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='Espionage'>Espionage</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='7'>7</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='5000000'>5000000</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='2.0'>2.0</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='[&#39;Bumble&#39;,⸱&#39;Goldback&#39;]'>[&#39;Bumble&#39;,⸱&#39;Goldback&#39;]</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='10.642707,-71.612534'>10.642707,-71.612534</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='1980/04/10'>1980/04/10</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='2015/08/10'>2015/08/10</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='[5.334000110626221,⸱2000.0]'>[5.334000110626221,⸱2000.0]</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='2015-08-10'>2015-08-10</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='2014-06-24⸱00:00:00'>2014-06-24⸱00:00:00</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='True'>True</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='bytearray(b&#39;Espionage&#39;)'>bytearray(b&#39;Espionage&#39;)</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='None'>None</div>\n",
       "        </td>\n",
       "        \n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        \n",
       "        <td>\n",
       "            <div title='ironhide&amp;'>ironhide&amp;</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='26'>26</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='Security'>Security</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='7'>7</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='5000000'>5000000</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='4.0'>4.0</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='[&#39;Roadbuster&#39;]'>[&#39;Roadbuster&#39;]</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='37.789563,-122.400356'>37.789563,-122.400356</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='1980/04/10'>1980/04/10</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='2014/07/10'>2014/07/10</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='[7.924799919128418,⸱4000.0]'>[7.924799919128418,⸱4000.0]</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='2014-06-24'>2014-06-24</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='2014-06-24⸱00:00:00'>2014-06-24⸱00:00:00</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='True'>True</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='bytearray(b&#39;Security&#39;)'>bytearray(b&#39;Security&#39;)</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='None'>None</div>\n",
       "        </td>\n",
       "        \n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        \n",
       "        <td>\n",
       "            <div title='Jazz'>Jazz</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='13'>13</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='First⸱Lieutenant'>First⸱Lieutenant</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='8'>8</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='5000000'>5000000</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='1.7999999523162842'>1.7999999523162842</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='[&#39;Meister&#39;]'>[&#39;Meister&#39;]</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='33.670666,-117.841553'>33.670666,-117.841553</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='1980/04/10'>1980/04/10</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='2013/06/10'>2013/06/10</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='[3.962399959564209,⸱1800.0]'>[3.962399959564209,⸱1800.0]</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='2013-06-24'>2013-06-24</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='2014-06-24⸱00:00:00'>2014-06-24⸱00:00:00</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='True'>True</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='bytearray(b&#39;First⸱Lieutenant&#39;)'>bytearray(b&#39;First⸱Lieutenant&#39;)</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='None'>None</div>\n",
       "        </td>\n",
       "        \n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        \n",
       "        <td>\n",
       "            <div title='Megatron'>Megatron</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='None'>None</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='None'>None</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='10'>10</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='5000000'>5000000</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='5.699999809265137'>5.699999809265137</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='[&#39;Megatron&#39;]'>[&#39;Megatron&#39;]</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='None'>None</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='1980/04/10'>1980/04/10</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='2012/05/10'>2012/05/10</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='[None,⸱5700.0]'>[None,⸱5700.0]</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='2012-05-10'>2012-05-10</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='2014-06-24⸱00:00:00'>2014-06-24⸱00:00:00</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='True'>True</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='bytearray(b&#39;None&#39;)'>bytearray(b&#39;None&#39;)</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='None'>None</div>\n",
       "        </td>\n",
       "        \n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        \n",
       "        <td>\n",
       "            <div title='Metroplex_)^$'>Metroplex_)^$</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='300'>300</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='Battle⸱Station'>Battle⸱Station</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='8'>8</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='5000000'>5000000</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='None'>None</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='[&#39;Metroflex&#39;]'>[&#39;Metroflex&#39;]</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='None'>None</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='1980/04/10'>1980/04/10</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='2011/04/10'>2011/04/10</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='[91.44000244140625,⸱None]'>[91.44000244140625,⸱None]</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='2011-04-10'>2011-04-10</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='2014-06-24⸱00:00:00'>2014-06-24⸱00:00:00</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='True'>True</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='bytearray(b&#39;Battle⸱Station&#39;)'>bytearray(b&#39;Battle⸱Station&#39;)</div>\n",
       "        </td>\n",
       "        \n",
       "        <td>\n",
       "            <div title='None'>None</div>\n",
       "        </td>\n",
       "        \n",
       "    </tr>\n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "\n",
       "\n",
       "<div class=\"info_items\">Viewing 6 of 6 rows / 16 columns</div>\n",
       "<div class=\"info_items\">8 partition(s)</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.types import *\n",
    "from datetime import date, datetime\n",
    "\n",
    "\n",
    "cols = [\n",
    "        (\"names\", \"str\"),\n",
    "        (\"height(ft)\", ShortType()),\n",
    "        (\"function\", \"str\"),\n",
    "        (\"rank\", ByteType()),\n",
    "        (\"age\", \"int\"),\n",
    "        (\"weight(t)\", \"float\"),\n",
    "        \"japanese name\",\n",
    "        \"last position seen\",\n",
    "        \"date arrival\",\n",
    "        \"last date seen\",\n",
    "        (\"attributes\", ArrayType(FloatType())),\n",
    "        (\"Date Type\", DateType()),\n",
    "        (\"Tiemstamp\", TimestampType()),\n",
    "        (\"Cybertronian\", BooleanType()),\n",
    "        (\"function(binary)\", BinaryType()),\n",
    "        (\"NullType\", NullType())\n",
    "\n",
    "    ]\n",
    "\n",
    "rows = [\n",
    "        (\"Optim'us\", 28, \"Leader\", 10, 5000000, 4.30, [\"Inochi\", \"Convoy\"], \"19.442735,-99.201111\", \"1980/04/10\",\n",
    "         \"2016/09/10\", [8.5344, 4300.0], date(2016, 9, 10), datetime(2014, 6, 24), True, bytearray(\"Leader\", \"utf-8\"),\n",
    "         None),\n",
    "        (\"bumbl#ebéé  \", 17, \"Espionage\", 7, 5000000, 2.0, [\"Bumble\", \"Goldback\"], \"10.642707,-71.612534\", \"1980/04/10\",\n",
    "         \"2015/08/10\", [5.334, 2000.0], date(2015, 8, 10), datetime(2014, 6, 24), True, bytearray(\"Espionage\", \"utf-8\"),\n",
    "         None),\n",
    "        (\"ironhide&\", 26, \"Security\", 7, 5000000, 4.0, [\"Roadbuster\"], \"37.789563,-122.400356\", \"1980/04/10\",\n",
    "         \"2014/07/10\", [7.9248, 4000.0], date(2014, 6, 24), datetime(2014, 6, 24), True, bytearray(\"Security\", \"utf-8\"),\n",
    "         None),\n",
    "        (\"Jazz\", 13, \"First Lieutenant\", 8, 5000000, 1.80, [\"Meister\"], \"33.670666,-117.841553\", \"1980/04/10\",\n",
    "         \"2013/06/10\", [3.9624, 1800.0], date(2013, 6, 24), datetime(2014, 6, 24), True,\n",
    "         bytearray(\"First Lieutenant\", \"utf-8\"), None),\n",
    "        (\"Megatron\", None, \"None\", 10, 5000000, 5.70, [\"Megatron\"], None, \"1980/04/10\", \"2012/05/10\", [None, 5700.0],\n",
    "         date(2012, 5, 10), datetime(2014, 6, 24), True, bytearray(\"None\", \"utf-8\"), None),\n",
    "        (\"Metroplex_)^$\", 300, \"Battle Station\", 8, 5000000, None, [\"Metroflex\"], None, \"1980/04/10\", \"2011/04/10\",\n",
    "         [91.44, None], date(2011, 4, 10), datetime(2014, 6, 24), True, bytearray(\"Battle Station\", \"utf-8\"), None),\n",
    "\n",
    "    ]\n",
    "df = op.create.df(cols ,rows)\n",
    "df.table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End Init Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimus Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Test(op, None, \"Optimus\", imports=[\"import datetime\",\n",
    "                                \"from pyspark.sql import functions as F\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test_create_df_one_column() test function...\n",
      "Creating test_create_df_plain() test function...\n",
      "Creating test_create_df_plain_infer_false() test function...\n",
      "Creating test_create_df_with_data_types() test function...\n",
      "Creating test_create_df_nullable() test function...\n",
      "Creating file test_Optimus.py\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "one_column = {\"rows\":[\"Argenis\", \"Favio\", \"Matthew\"], \"cols\":[\"name\"]}\n",
    "plain = {\"rows\":[(\"BOB\", 1),(\"JoSe\", 2)],\"cols\":[\"name\",\"age\"]}\n",
    "plain_infer_false = {\"rows\":[(\"BOB\", 1),(\"JoSe\", 2)],\"cols\":[\"name\",\"age\"],\"infer_schema\":False}\n",
    "with_data_types = {\"rows\":[(\"BOB\", 1),(\"JoSe\", 2)],\"cols\":[(\"name\", StringType(), True),(\"age\", IntegerType(), False)]}\n",
    "nullable = {\"rows\":[(\"BOB\", 1),(\"JoSe\", 2)],\"cols\":[(\"name\", StringType()),(\"age\", IntegerType())]}\n",
    "\n",
    "df1 = op.create.df(**one_column)\n",
    "df2 = op.create.df(**plain)\n",
    "df3 = op.create.df(**plain_infer_false)\n",
    "df4 = op.create.df(**with_data_types)\n",
    "df5 = op.create.df(**nullable)\n",
    "\n",
    "t.run(\n",
    "\n",
    "    t.create(df1, None, \"one_column\", \"df\", **one_column),\n",
    "    t.create(df2, None, \"plain\", \"df\", **plain),\n",
    "    t.create(df3, None, \"plain_infer_false\", \"df\", **plain_infer_false),\n",
    "    t.create(df4, None, \"with_data_types\", \"df\", **with_data_types),\n",
    "    t.create(df5, None, \"nullable\", \"df\", **nullable),\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Test(op, df, \"df_cols\", imports=[\"from pyspark.ml.linalg import Vectors, VectorUDT, DenseVector\",\n",
    "                                        \"import numpy as np\",\n",
    "                                        \"nan = np.nan\",\n",
    "                                        \"import datetime\",\n",
    "                                        \"from pyspark.sql import functions as F\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test_cols_min() test function...\n",
      "Creating test_cols_min_all_columns() test function...\n",
      "Creating test_cols_max() test function...\n",
      "Creating test_cols_max_all_columns() test function...\n",
      "Creating test_cols_range() test function...\n",
      "Creating test_cols_range_all_columns() test function...\n",
      "Creating test_cols_median() test function...\n",
      "Creating test_cols_median_all_columns() test function...\n",
      "Creating test_cols_percentile() test function...\n",
      "Creating test_cols_percentile_all_columns() test function...\n",
      "Creating test_cols_mad() test function...\n",
      "Creating test_cols_mad_all_columns() test function...\n",
      "Creating test_cols_std() test function...\n",
      "Creating test_cols_std_all_columns() test function...\n",
      "Creating test_cols_kurt() test function...\n",
      "Creating test_cols_kurt_all_columns() test function...\n",
      "Creating test_cols_mean() test function...\n",
      "Creating test_cols_mean_all_columns() test function...\n",
      "Creating test_cols_skewness() test function...\n",
      "Creating test_cols_skewness_all_columns() test function...\n",
      "Creating test_cols_sum() test function...\n",
      "Creating test_cols_sum_all_columns() test function...\n",
      "Creating test_cols_variance() test function...\n",
      "Creating test_cols_variance_all_columns() test function...\n",
      "Creating test_cols_abs() test function...\n",
      "Creating test_cols_abs_all_columns() test function...\n",
      "Creating test_cols_mode() test function...\n",
      "Creating test_cols_mode_all_columns() test function...\n",
      "Creating test_cols_count() test function...\n",
      "Creating test_cols_count_na() test function...\n",
      "Creating test_cols_count_na_all_columns() test function...\n",
      "Creating test_cols_count_zeros() test function...\n",
      "Creating test_cols_count_zeros_all_columns() test function...\n",
      "Creating test_cols_count_uniques() test function...\n",
      "Creating test_cols_count_uniques_all_columns() test function...\n",
      "Creating test_cols_unique() test function...\n",
      "Creating test_cols_unique_all_columns() test function...\n",
      "Creating test_cols_add() test function...\n",
      "Creating test_cols_add_all_columns() test function...\n",
      "Creating test_cols_sub() test function...\n",
      "Creating test_cols_sub_all_columns() test function...\n",
      "Creating test_cols_mul() test function...\n",
      "Creating test_cols_mul_all_columns() test function...\n",
      "Creating test_cols_div() test function...\n",
      "Creating test_cols_div_all_columns() test function...\n",
      "Creating test_cols_z_score() test function...\n",
      "Creating test_cols_z_score_all_columns() test function...\n",
      "Creating test_cols_iqr() test function...\n",
      "Creating test_cols_iqr_all_columns() test function...\n",
      "Creating test_cols_lower() test function...\n",
      "Creating test_cols_lower_all_columns() test function...\n",
      "Creating test_cols_upper() test function...\n",
      "Creating test_cols_upper_all_columns() test function...\n",
      "Creating test_cols_trim() test function...\n",
      "Creating test_cols_trim_all_columns() test function...\n",
      "Creating test_cols_reverse() test function...\n",
      "Creating test_cols_reverse_all_columns() test function...\n",
      "Creating test_cols_remove_accents() test function...\n",
      "Creating test_cols_remove_accents_all_columns() test function...\n",
      "Creating test_cols_remove_special_chars() test function...\n",
      "Creating test_cols_remove_special_chars_all_columns() test function...\n",
      "Creating test_cols_remove_white_spaces() test function...\n",
      "Creating test_cols_remove_white_spaces_all_columns() test function...\n",
      "Creating test_cols_date_transform() test function...\n",
      "Creating test_cols_date_transform_all_columns() test function...\n",
      "Creating test_cols_years_between() test function...\n",
      "Creating test_cols_years_between_multiple_columns() test function...\n",
      "Creating test_cols_impute() test function...\n",
      "Creating test_cols_impute_all_columns() test function...\n",
      "Creating test_cols_hist() test function...\n",
      "Creating test_cols_frequency() test function...\n",
      "Creating test_cols_frequency_all_columns() test function...\n",
      "Creating test_cols_schema_dtype() test function...\n",
      "Creating test_cols_dtypes() test function...\n",
      "Creating test_cols_dtypes_all_columns() test function...\n",
      "Creating test_cols_select_by_dtypes_str() test function...\n",
      "Creating test_cols_select_by_dtypes_int() test function...\n",
      "Creating test_cols_select_by_dtypes_float() test function...\n",
      "Creating test_cols_select_by_dtypes_array() test function...\n",
      "Creating test_cols_names() test function...\n",
      "Creating test_cols_qcut() test function...\n",
      "Creating test_cols_qcut_all_columns() test function...\n",
      "Creating test_cols_clip() test function...\n",
      "Creating test_cols_clip_all_columns() test function...\n",
      "Creating test_cols_replace() test function...\n",
      "Creating test_cols_replace_all_columns() test function...\n",
      "Creating test_cols_apply_expr() test function...\n",
      "Creating test_cols_apply_expr_all_columns() test function...\n",
      "Creating test_cols_append_number() test function...\n",
      "Creating test_cols_rename() test function...\n",
      "Creating test_cols_rename_list() test function...\n",
      "Creating test_cols_rename_function() test function...\n",
      "Creating test_cols_drop() test function...\n",
      "Creating test_cols_cast() test function...\n",
      "Creating test_cols_cast_all_columns() test function...\n",
      "Creating test_cols_cast_vector() test function...\n",
      "Creating test_cols_keep() test function...\n",
      "Creating test_cols_move_after() test function...\n",
      "Creating test_cols_move_before() test function...\n",
      "Creating test_cols_move_beginning() test function...\n",
      "Creating test_cols_move_end() test function...\n",
      "Creating test_cols_select() test function...\n",
      "Creating test_cols_select_regex() test function...\n",
      "Creating test_cols_sort() test function...\n",
      "Creating test_cols_sort_desc() test function...\n",
      "Creating test_cols_sort_asc() test function...\n",
      "Creating test_cols_fill_na() test function...\n",
      "Creating test_cols_fill_na_all_columns() test function...\n",
      "Creating test_cols_nest() test function...\n",
      "Creating test_cols_nest_vector() test function...\n",
      "Creating test_cols_nest_array() test function...\n",
      "Creating test_cols_unnest_array_all_columns() test function...\n",
      "Creating test_cols_unnest_array() test function...\n",
      "Creating test_cols_unnest_array_all_columns() test function...\n",
      "Creating test_cols_is_na_all_columns() test function...\n",
      "Creating test_cols_is_na() test function...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "def func(col_name, attrs):\n",
    "    return F.col(col_name) * 2\n",
    "\n",
    "numeric_col = \"height(ft)\"\n",
    "numeric_col_B = \"rank\"\n",
    "numeric_col_C = \"rank\"\n",
    "string_col = \"function\"\n",
    "data_col = \"date arrival\"\n",
    "data_col_B = \"last date seen\"\n",
    "new_col = \"new col\"\n",
    "array_col = \"attributes\"\n",
    "\n",
    "t.run(\n",
    "    \n",
    "    t.create(None, \"cols.min\", None, \"json\", numeric_col),\n",
    "    t.create(None, \"cols.min\", \"all_columns\", \"json\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.max\", None, \"json\", numeric_col),\n",
    "    t.create(None, \"cols.max\", \"all_columns\", \"json\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.range\", None, \"json\", numeric_col),\n",
    "    t.create(None, \"cols.range\", \"all_columns\", \"json\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.median\", None, \"json\", numeric_col),\n",
    "    t.create(None, \"cols.median\", \"all_columns\", \"json\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.percentile\", None, \"json\", numeric_col, [0.05, 0.25], 1),\n",
    "    t.create(None, \"cols.percentile\", \"all_columns\", \"json\", \"*\", [0.05, 0.25], 1),\n",
    "\n",
    "    t.create(None, \"cols.mad\", None, \"json\", numeric_col),\n",
    "    t.create(None, \"cols.mad\", \"all_columns\", \"json\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.std\", None, \"json\", numeric_col),\n",
    "    t.create(None, \"cols.std\", \"all_columns\", \"json\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.kurt\", None, \"json\", numeric_col),\n",
    "    t.create(None, \"cols.kurt\", \"all_columns\", \"json\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.mean\", None, \"json\", numeric_col),\n",
    "    t.create(None, \"cols.mean\", \"all_columns\", \"json\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.skewness\", None, \"json\", numeric_col),\n",
    "    t.create(None, \"cols.skewness\", \"all_columns\", \"json\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.sum\", None, \"json\", numeric_col),\n",
    "    t.create(None, \"cols.sum\", \"all_columns\", \"json\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.variance\", None, \"json\", numeric_col),\n",
    "    t.create(None, \"cols.variance\", \"all_columns\", \"json\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.abs\", None, \"df\", numeric_col),\n",
    "    t.create(None, \"cols.abs\", \"all_columns\", \"df\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.mode\", None, \"json\", numeric_col),\n",
    "    t.create(None, \"cols.mode\", \"all_columns\", \"json\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.count\", None, \"json\"),\n",
    "\n",
    "    t.create(None, \"cols.count_na\", None, \"json\", numeric_col),\n",
    "    t.create(None, \"cols.count_na\", \"all_columns\", \"json\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.count_zeros\", None, \"json\", numeric_col),\n",
    "    t.create(None, \"cols.count_zeros\", \"all_columns\", \"json\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.count_uniques\", None, \"json\", numeric_col),\n",
    "    t.create(None, \"cols.count_uniques\", \"all_columns\", \"json\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.unique\", None, \"df\", numeric_col),\n",
    "    t.create(None, \"cols.unique\", \"all_columns\", \"df\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.z_score\", None, \"df\", numeric_col),\n",
    "    t.create(None, \"cols.z_score\", \"all_columns\", \"df\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.iqr\", None, \"json\", numeric_col),\n",
    "    t.create(None, \"cols.iqr\", \"all_columns\", \"json\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.lower\", None, \"df\", numeric_col),\n",
    "    t.create(None, \"cols.lower\", \"all_columns\", \"df\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.upper\", None, \"df\", numeric_col),\n",
    "    t.create(None, \"cols.upper\", \"all_columns\", \"df\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.trim\", None, \"df\", numeric_col),\n",
    "\n",
    "    t.create(None, \"cols.trim\", \"all_columns\", \"df\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.reverse\", None, \"df\", numeric_col),\n",
    "    t.create(None, \"cols.reverse\", \"all_columns\", \"df\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.remove_accents\", None, \"df\", numeric_col),\n",
    "    t.create(None, \"cols.remove_accents\", \"all_columns\", \"df\", \"Date Type\"),\n",
    "\n",
    "    t.create(None, \"cols.remove_special_chars\", None, \"df\", numeric_col),\n",
    "    t.create(None, \"cols.remove_special_chars\", \"all_columns\", \"df\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.remove_white_spaces\", None, \"df\", numeric_col),\n",
    "    t.create(None, \"cols.remove_white_spaces\", \"all_columns\", \"df\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.date_transform\", None, \"df\", data_col, \"yyyy/MM/dd\", \"dd-MM-YYYY\"),\n",
    "    t.create(None, \"cols.date_transform\", \"all_columns\", \"df\", [data_col, data_col_B], \"yyyy/MM/dd\", \"dd-MM-YYYY\"),\n",
    "\n",
    "    t.create(None, \"cols.years_between\", None, \"df\", data_col, \"yyyyMMdd\"),\n",
    "    t.create(None, \"cols.years_between\", \"multiple_columns\", \"df\", [data_col, data_col_B], \"yyyyMMdd\"),\n",
    "\n",
    "    # ---\n",
    "\n",
    "    t.create(None, \"cols.impute\", None, \"df\", numeric_col_B),\n",
    "    t.create(None, \"cols.impute\", \"all_columns\", \"df\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.hist\", None, \"json\", numeric_col_B, 4),\n",
    "    #t.create(None,\"cols.hist\",\"all_columns\",\"df\",\"*\",4),\n",
    "\n",
    "    t.create(None, \"cols.frequency\", None, \"json\", numeric_col_B, 4),\n",
    "    t.create(None, \"cols.frequency\", \"all_columns\", \"json\", \"*\", 4),\n",
    "\n",
    "    t.create(None, \"cols.schema_dtype\", None, \"json\", numeric_col_B),\n",
    "    #t.create(None, \"cols.schema_dtype\", \"all_columns\", \"json\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.dtypes\", None, \"json\", numeric_col_B),\n",
    "    t.create(None, \"cols.dtypes\", \"all_columns\", \"json\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.select_by_dtypes\", \"str\", \"df\", \"str\"),\n",
    "    t.create(None, \"cols.select_by_dtypes\", \"int\", \"df\", \"int\"),\n",
    "    t.create(None, \"cols.select_by_dtypes\", \"float\", \"df\", \"float\"),\n",
    "    t.create(None, \"cols.select_by_dtypes\", \"array\", \"df\", \"array\"),\n",
    "\n",
    "    t.create(None, \"cols.names\", None, \"json\"),\n",
    "\n",
    "    t.create(None, \"cols.qcut\", None, \"df\", numeric_col_B, 4),\n",
    "    t.create(None, \"cols.qcut\", \"all_columns\", \"df\", \"*\", 4),\n",
    "\n",
    "    t.create(None, \"cols.clip\", None, \"df\", numeric_col_B, 3, 5),\n",
    "    t.create(None, \"cols.clip\", \"all_columns\", \"df\", \"*\", 3, 5),\n",
    "\n",
    "    t.create(None, \"cols.replace\", None, \"df\", string_col, [(\"Security\", \"Leader\")], \"Match\"),\n",
    "    t.create(None, \"cols.replace\", \"all_columns\", \"df\", \"*\", [(\"Jazz\", \"Leader\")], \"Match\"),\n",
    "\n",
    "    t.create(None, \"cols.apply_expr\", None, \"df\", numeric_col_B, func),\n",
    "    t.create(None, \"cols.apply_expr\", \"all_columns\", \"df\", [numeric_col_B,numeric_col_C], func),\n",
    "\n",
    "    t.create(None, \"cols.append\", \"number\", \"df\", new_col, 1),\n",
    "\n",
    "    #t.create(None, \"cols.append\", \"advance\", \"df\", [(\"new_col_4\", \"test\"),\n",
    "    #                                                (\"new_col_5\", df[numeric_col_B] * 2),\n",
    "    #                                                (\"new_col_6\", [1, 2, 3])\n",
    "    #                                                ]),\n",
    "\n",
    "    t.create(None, \"cols.rename\", None, \"df\", numeric_col_B, numeric_col_B + \"(old)\"),\n",
    "    t.create(None, \"cols.rename\", \"list\", \"df\",\n",
    "             [numeric_col, numeric_col + \"(tons)\", numeric_col_B, numeric_col_B + \"(old)\"]),\n",
    "    t.create(None, \"cols.rename\", \"function\", \"df\", str.upper),\n",
    "\n",
    "    t.create(None, \"cols.drop\", None, \"df\", numeric_col_B),\n",
    "\n",
    "    t.create(None, \"cols.cast\", None, \"df\", string_col, \"string\"),\n",
    "    t.create(None, \"cols.cast\", \"all_columns\", \"df\", \"*\", \"string\"),\n",
    "    t.create(None, \"cols.cast\", \"vector\", \"df\", array_col, Vectors),\n",
    "\n",
    "    t.create(None, \"cols.keep\", None, \"df\", numeric_col_B),\n",
    "\n",
    "    t.create(None, \"cols.move\", \"after\", \"df\", numeric_col_B, \"after\", array_col),\n",
    "    t.create(None, \"cols.move\", \"before\", \"df\", numeric_col_B, \"before\", array_col),\n",
    "    t.create(None, \"cols.move\", \"beginning\", \"df\", numeric_col_B, \"beginning\"),\n",
    "    t.create(None, \"cols.move\", \"end\", \"df\", numeric_col_B, \"end\"),\n",
    "\n",
    "    t.create(None, \"cols.select\", None, \"df\", 0, numeric_col),\n",
    "\n",
    "    t.create(None, \"cols.select\", \"regex\", \"df\", \"n.*\", regex=True),\n",
    "\n",
    "    t.create(None, \"cols.sort\", None, \"df\"),\n",
    "    t.create(None, \"cols.sort\", \"desc\", \"df\", \"desc\"),\n",
    "    t.create(None, \"cols.sort\", \"asc\", \"df\", \"asc\"),\n",
    "\n",
    "    t.create(None, \"cols.fill_na\", None, \"df\", numeric_col, \"N/A\"),\n",
    "    t.create(None, \"cols.fill_na\", \"all_columns\", \"df\", \"*\", \"N/A\"),\n",
    "\n",
    "    t.create(None, \"cols.nest\", None, \"df\", [numeric_col, numeric_col_B], new_col, separator=\" \"),\n",
    "    #t.create(None, \"cols.nest\", \"mix\", \"df\", [F.col(numeric_col), F.col(numeric_col_B)], \"E\", separator=\"--\"),\n",
    "\n",
    "    #t.create(None, \"cols.nest\", \"vector_all_columns\", \"df\", [numeric_col, numeric_col_B], new_col, shape=\"vector\"),\n",
    "    t.create(None, \"cols.nest\", \"vector\", \"df\", [numeric_col_C, numeric_col_B], new_col, shape=\"vector\"),\n",
    "\n",
    "    #t.create(None, \"cols.nest\", \"array_all_columns\", \"df\", \"*\", new_col, shape=\"array\"),\n",
    "    t.create(None, \"cols.nest\", \"array\", \"df\", [numeric_col, numeric_col_B,numeric_col_C], new_col, shape=\"array\"),\n",
    "\n",
    "    t.create(None, \"cols.unnest\", \"array_all_columns\", \"df\", array_col, \"-\", index=1),\n",
    "    t.create(None, \"cols.unnest\", \"array\", \"df\", array_col),\n",
    "    t.create(None, \"cols.unnest\", \"array_all_columns\", \"df\", array_col),\n",
    "\n",
    "    t.create(None, \"cols.is_na\", \"all_columns\", \"df\", \"*\"),\n",
    "    t.create(None, \"cols.is_na\", None, \"df\", numeric_col),\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cols Tests 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Test(op, df, \"df_cols_2\", imports=[\"from pyspark.ml.linalg import Vectors, VectorUDT, DenseVector\",\n",
    "                                        \"import numpy as np\",\n",
    "                                        \"nan = np.nan\",\n",
    "                                        \"import datetime\",\n",
    "                                        \"from pyspark.sql import functions as F\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test_cols_add() test function...\n",
      "Creating test_cols_add_all_columns() test function...\n",
      "Creating test_cols_sub() test function...\n",
      "Creating test_cols_sub_all_columns() test function...\n",
      "Creating test_cols_mul() test function...\n",
      "Creating test_cols_div() test function...\n",
      "Creating file test_df_cols_2.py\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def func(col_name, attrs):\n",
    "    return F.col(col_name) * 2\n",
    "\n",
    "numeric_col = \"height(ft)\"\n",
    "numeric_col_B = \"rank\"\n",
    "numeric_col_C = \"rank\"\n",
    "string_col = \"function\"\n",
    "data_col = \"date arrival\"\n",
    "data_col_B = \"last date seen\"\n",
    "new_col = \"new col\"\n",
    "array_col = \"attributes\"\n",
    "\n",
    "t.run(\n",
    "    t.create(None, \"cols.add\", None, \"df\", [numeric_col, numeric_col_B]),\n",
    "    t.create(None, \"cols.add\", \"all_columns\", \"df\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.sub\", None, \"df\", [numeric_col, numeric_col_B]),\n",
    "    t.create(None, \"cols.sub\", \"all_columns\", \"df\", \"*\"),\n",
    "\n",
    "    t.create(None, \"cols.mul\", None, \"df\", [numeric_col, numeric_col_B]),\n",
    "#     t.create(None, \"cols.mul\", \"all_columns\", \"df\", \"*\"), Error with precision number\n",
    "\n",
    "    t.create(None, \"cols.div\", None, \"df\", [numeric_col, numeric_col_B]),\n",
    "#     t.create(None, \"cols.div\", \"all_columns\", \"df\", \"*\"), Error with precision number\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rows Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Test(op,df, \"df_rows\", imports=[\"from pyspark.ml.linalg import Vectors, VectorUDT, DenseVector\",\n",
    "                                         \"import numpy as np\",\n",
    "                                        \"nan = np.nan\",\n",
    "                                        \"import datetime\",\n",
    "                                        \"from pyspark.sql import functions as F\",\n",
    "                                        \"from optimus.functions import abstract_udf as audf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [\n",
    "        (\"Optim'us\", 28, \"Leader\", 10, 5000000, 4.30, [\"Inochi\", \"Convoy\"], \"19.442735,-99.201111\", \"1980/04/10\",\n",
    "         \"2016/09/10\", [8.5344, 4300.0], date(2016, 9, 10), datetime(2014, 6, 24), True, bytearray(\"Leader\", \"utf-8\"),\n",
    "         None)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = op.load.url(\"https://raw.githubusercontent.com/ironmussa/Optimus/master/examples/data/foo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Test(op, df, \"op_io\", imports=[\"from pyspark.ml.linalg import Vectors, VectorUDT, DenseVector\",\n",
    "                                        \"import numpy as np\",\n",
    "                                        \"nan = np.nan\",\n",
    "                                        \"import datetime\",\n",
    "                                        \"from pyspark.sql import functions as F\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test_load_csv() test function...\n",
      "Creating test_load_json() test function...\n",
      "Creating test_load_parquet() test function...\n",
      "Creating test_load_url_csv() test function...\n",
      "Creating test_load_url_json() test function...\n",
      "Creating test_load_url_parquet() test function...\n",
      "Creating test_save_csv() test function...\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1866.csv.\n: java.lang.UnsupportedOperationException: CSV data source does not support array<string> data type.\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVUtils$.org$apache$spark$sql$execution$datasources$csv$CSVUtils$$verifyType$1(CSVUtils.scala:127)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVUtils$$anonfun$verifySchema$1.apply(CSVUtils.scala:131)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVUtils$$anonfun$verifySchema$1.apply(CSVUtils.scala:131)\r\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\r\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1336)\r\n\tat scala.collection.IterableLike$class.foreach(IterableLike.scala:72)\r\n\tat org.apache.spark.sql.types.StructType.foreach(StructType.scala:99)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVUtils$.verifySchema(CSVUtils.scala:131)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.prepareWrite(CSVFileFormat.scala:65)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:140)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:154)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)\r\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:654)\r\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:654)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:654)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:273)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:267)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:225)\r\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:642)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-9434069f96ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"load.url\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"parquet\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"df\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"https://raw.githubusercontent.com/ironmussa/Optimus/master/examples/data/foo.parquet\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"parquet\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m      \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"save.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"test.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m      \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"save.json\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"test.json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m      \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"save.parquet\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"test.parquet\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Optimus\\optimus\\helpers\\test.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, df, func, suffix, output, *args, **kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m                 \u001b[0mdf_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m             \u001b[0mdf_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"df\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Optimus\\optimus\\helpers\\decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m             \u001b[0m_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlog_time\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Optimus\\optimus\\io\\save.py\u001b[0m in \u001b[0;36mcsv\u001b[1;34m(path, header, mode, sep, num_partitions)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_partitions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\sql\\readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[1;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping)\u001b[0m\n\u001b[0;32m    883\u001b[0m                        \u001b[0mignoreTrailingWhiteSpace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignoreTrailingWhiteSpace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m                        charToEscapeQuoteEscaping=charToEscapeQuoteEscaping)\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0msince\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1257\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o1866.csv.\n: java.lang.UnsupportedOperationException: CSV data source does not support array<string> data type.\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVUtils$.org$apache$spark$sql$execution$datasources$csv$CSVUtils$$verifyType$1(CSVUtils.scala:127)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVUtils$$anonfun$verifySchema$1.apply(CSVUtils.scala:131)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVUtils$$anonfun$verifySchema$1.apply(CSVUtils.scala:131)\r\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\r\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1336)\r\n\tat scala.collection.IterableLike$class.foreach(IterableLike.scala:72)\r\n\tat org.apache.spark.sql.types.StructType.foreach(StructType.scala:99)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVUtils$.verifySchema(CSVUtils.scala:131)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.prepareWrite(CSVFileFormat.scala:65)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:140)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:154)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)\r\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:654)\r\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:654)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:654)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:273)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:267)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:225)\r\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:642)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n"
     ]
    }
   ],
   "source": [
    "t.run(\n",
    "    \n",
    "    t.create(op, \"load.csv\", None, \"df\", \"../examples/data/foo.csv\"),\n",
    "    t.create(op, \"load.json\", None, \"df\", \"../examples/data/foo.json\"),\n",
    "    t.create(op, \"load.parquet\", None, \"df\", \"../examples/data/foo.parquet\"),\n",
    "\n",
    "    t.create(op, \"load.url\", \"csv\", \"df\", \"https://raw.githubusercontent.com/ironmussa/Optimus/master/examples/data/foo.csv\"),\n",
    "    t.create(op, \"load.url\", \"json\", \"df\", \"https://raw.githubusercontent.com/ironmussa/Optimus/master/examples/data/foo.json\",\"json\"),\n",
    "    t.create(op, \"load.url\", \"parquet\", \"df\", \"https://raw.githubusercontent.com/ironmussa/Optimus/master/examples/data/foo.parquet\",\"parquet\"),\n",
    "    \n",
    "     t.create(None, \"save.csv\", None, None, \"test.csv\"),\n",
    "     t.create(None, \"save.json\", None, None, \"test.json\"),\n",
    "     t.create(None, \"save.parquet\", None, None, \"test.parquet\"),\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.3",
    "jupytext_version": "0.8.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
