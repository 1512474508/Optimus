{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPreprocessing(ds):\n",
    "    df_stat = pd.DataFrame()\n",
    "    df_stat = ds\n",
    "    df_stat = df_stat.dropna()\n",
    "    df_stat['length']= df_stat.apply(lambda r: len(str(r.Text)), axis=1)\n",
    "    df_stat['frac_numcells']  = df_stat.apply(lambda r: len(re.findall('[0-9]',str(r.Text)))/len(r.Text), axis=1)\n",
    "    df_stat['frac_floatcells']  = df_stat.apply(lambda r: len(re.findall('\\.]',str(r.Text)))/len(r.Text), axis=1)\n",
    "    df_stat['frac_textcells']  = df_stat.apply(lambda r: len(re.findall('[a-z]|[A-Z][\\.]',str(r.Text)))/len(r.Text), axis=1)\n",
    "    df_stat['frac_speccells']  = df_stat.apply(lambda r: len(re.findall('[\\\\@\\-:]',str(r.Text)))/len(r.Text), axis=1)\n",
    "    return df_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 1.5830 - accuracy: 0.4391 - val_loss: 1.3142 - val_accuracy: 0.4939\n",
      "Epoch 2/25\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1492 - accuracy: 0.5887 - val_loss: 1.0072 - val_accuracy: 0.6067\n",
      "Epoch 3/25\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.9329 - accuracy: 0.6340 - val_loss: 0.8968 - val_accuracy: 0.5703\n",
      "Epoch 4/25\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8251 - accuracy: 0.6427 - val_loss: 0.7978 - val_accuracy: 0.5612\n",
      "Epoch 5/25\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7531 - accuracy: 0.6690 - val_loss: 0.7409 - val_accuracy: 0.6806\n",
      "Epoch 6/25\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6976 - accuracy: 0.6764 - val_loss: 0.6903 - val_accuracy: 0.6442\n",
      "Epoch 7/25\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6466 - accuracy: 0.6919 - val_loss: 0.6314 - val_accuracy: 0.6570\n",
      "Epoch 8/25\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6072 - accuracy: 0.6860 - val_loss: 0.5864 - val_accuracy: 0.6806\n",
      "Epoch 9/25\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.5804 - accuracy: 0.6872 - val_loss: 0.5993 - val_accuracy: 0.7200\n",
      "Epoch 10/25\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.6979 - val_loss: 0.5297 - val_accuracy: 0.6642\n",
      "Epoch 11/25\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7015 - val_loss: 0.5174 - val_accuracy: 0.6806\n",
      "Epoch 12/25\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7370 - val_loss: 0.4796 - val_accuracy: 0.7055\n",
      "Epoch 13/25\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7704 - val_loss: 0.4726 - val_accuracy: 0.6806\n",
      "Epoch 14/25\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7725 - val_loss: 0.4254 - val_accuracy: 0.8073\n",
      "Epoch 15/25\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8101 - val_loss: 0.4181 - val_accuracy: 0.8236\n",
      "Epoch 16/25\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8499 - val_loss: 0.3928 - val_accuracy: 0.8770\n",
      "Epoch 17/25\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3702 - accuracy: 0.8624 - val_loss: 0.3440 - val_accuracy: 0.9006\n",
      "Epoch 18/25\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.9048 - val_loss: 0.3438 - val_accuracy: 0.8485\n",
      "Epoch 19/25\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.9242 - val_loss: 0.2881 - val_accuracy: 0.9291\n",
      "Epoch 20/25\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.2812 - accuracy: 0.9439 - val_loss: 0.2708 - val_accuracy: 0.9218\n",
      "Epoch 21/25\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.9678 - val_loss: 0.2325 - val_accuracy: 0.9945\n",
      "Epoch 22/25\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2285 - accuracy: 0.9615 - val_loss: 0.2092 - val_accuracy: 0.9945\n",
      "Epoch 23/25\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1998 - accuracy: 0.9794 - val_loss: 0.2073 - val_accuracy: 0.9273\n",
      "Epoch 24/25\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1818 - accuracy: 0.9701 - val_loss: 0.1674 - val_accuracy: 1.0000\n",
      "Epoch 25/25\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.1620 - accuracy: 0.9875 - val_loss: 0.1446 - val_accuracy: 0.9945\n"
     ]
    }
   ],
   "source": [
    "origData = pd.read_csv('data.csv')\n",
    "df_stat = dataPreprocessing(origData)\n",
    "df_stat.drop(columns=['Text', ' Type'], inplace=True)\n",
    "\n",
    "enc = LabelEncoder()\n",
    "targets = enc.fit_transform(origData[' Type'])\n",
    "\n",
    "feature_columns = ['length', 'frac_numcells', 'frac_floatcells', 'frac_textcells', 'frac_speccells']\n",
    "\n",
    "#split the sequences into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_stat[feature_columns], \n",
    "                                                    targets, \n",
    "                                                    test_size=0.33, random_state=42)\n",
    "\n",
    "#Creating a keras Model\n",
    "model = Sequential([Dense(100, input_dim = len(feature_columns)),\n",
    "                    Dense(50, activation='relu'),\n",
    "                    Dense(len(np.unique(targets)), activation='softmax')])\n",
    "                   \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Training on the training set and validating on the test set\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    batch_size=32, shuffle=True, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Data\n",
    "in_data = ['10-Aug-2010', '4125-1245-4589-1245', '8-8-2010', '+1 707 6256967','27-8-20', '12121', \n",
    "           '27-8-2010','ab@gmail.com','5245454.12','2010/5/8 00:00:00',\n",
    "           'MJGylxLisc@aol.com',\"This is a string checking This is a string checking\",\"tyson@hi-bumblebee.com\",\n",
    "            \"argenis@hi-bumblebee.com\",\"bh@hi-bumblebee.com\",\"vaish@hi-bumblebee.com\",\n",
    "           '2010-5-08','+1 456 1234578']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class = ['DateTime'] for input  10-Aug-2010\n",
      "Predicted Class = ['CreditCard'] for input  4125-1245-4589-1245\n",
      "Predicted Class = ['DateTime'] for input  8-8-2010\n",
      "Predicted Class = ['PhoneNumber'] for input  +1 707 6256967\n",
      "Predicted Class = ['DateTime'] for input  27-8-20\n",
      "Predicted Class = ['Int'] for input  12121\n",
      "Predicted Class = ['DateTime'] for input  27-8-2010\n",
      "Predicted Class = ['DateTime'] for input  ab@gmail.com\n",
      "Predicted Class = ['Float'] for input  5245454.12\n",
      "Predicted Class = ['DateTime'] for input  2010/5/8 00:00:00\n",
      "Predicted Class = ['Email'] for input  MJGylxLisc@aol.com\n",
      "Predicted Class = ['String'] for input  This is a string checking This is a string checking\n",
      "Predicted Class = ['Email'] for input  tyson@hi-bumblebee.com\n",
      "Predicted Class = ['Email'] for input  argenis@hi-bumblebee.com\n",
      "Predicted Class = ['Email'] for input  bh@hi-bumblebee.com\n",
      "Predicted Class = ['Email'] for input  vaish@hi-bumblebee.com\n",
      "Predicted Class = ['DateTime'] for input  2010-5-08\n",
      "Predicted Class = ['PhoneNumber'] for input  +1 456 1234578\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.DataFrame(in_data, columns=['Text'])\n",
    "# data preprocessing for testing\n",
    "df_stat_test = dataPreprocessing(df_test)\n",
    "df_stat_test.drop(columns=['Text'], inplace=True)\n",
    "\n",
    "model.predict(df_stat_test)\n",
    "predicted_class  = np.argmax(model.predict(df_stat_test), axis=1)\n",
    "for row_count, value in enumerate(predicted_class):\n",
    "    print(\"Predicted Class =\" , enc.inverse_transform([value]), \"for input \", in_data[row_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
