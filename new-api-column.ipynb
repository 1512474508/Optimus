{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A beautifull way to work with data\n",
    "\n",
    "This is an API proposal to access data.\n",
    "\n",
    "Dataframes would have rows and columns. \n",
    "\n",
    "* To access columns just use df.cols()\n",
    "* To access rows just use df.rows()\n",
    "* I/O operations to load and save data are in Optimus. op.load.csv(). op.save.csv()\n",
    "\n",
    "Easy and simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimus import *\n",
    "\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, BooleanType, IntegerType, ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Optimus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-21bfb2eb8750>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create optimus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOptimus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Optimus' is not defined"
     ]
    }
   ],
   "source": [
    "# Create optimus\n",
    "op = Optimus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe\n",
    "### Spark\n",
    "\n",
    "This is ugly:\n",
    "\n",
    "```\n",
    "val someData = Seq(\n",
    "  Row(8, \"bat\"),\n",
    "  Row(64, \"mouse\"),\n",
    "  Row(-27, \"horse\")\n",
    ")\n",
    "\n",
    "val someSchema = List(\n",
    "  StructField(\"number\", IntegerType, true),\n",
    "  StructField(\"word\", StringType, true)\n",
    ")\n",
    "\n",
    "val someDF = spark.createDataFrame(\n",
    "  spark.sparkContext.parallelize(someData),\n",
    "  StructType(someSchema)\n",
    ")```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+-----+-------------+------+-----+\n",
      "|              words|num|animals|thing|  two strings|filter|num 2|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+\n",
      "|  I like     fish  |  1|    dog|housé|      cat-car|     a|    1|\n",
      "|            zombies|  2|    cat|   tv|       dog-tv|     b|    2|\n",
      "|simpsons   cat lady|  2|   frog|table|eagle-tv-plus|     1|    3|\n",
      "|               null|  3|  eagle|glass|      lion-pc|     c|    4|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Thanks Mr Powers\n",
    "df = op.create.df(\n",
    "            [\n",
    "                (\"words\", \"str\", True),\n",
    "                (\"num\", \"int\", True),\n",
    "                (\"animals\", \"str\", True),\n",
    "                (\"thing\", StringType(), True),\n",
    "                (\"two strings\", StringType(), True),\n",
    "                (\"filter\", StringType(), True),\n",
    "                (\"num 2\", \"string\", True)\n",
    "\n",
    "            ]\n",
    ",\n",
    "[\n",
    "                (\"  I like     fish  \", 1, \"dog\", \"housé\", \"cat-car\", \"a\",\"1\"),\n",
    "                (\"    zombies\", 2, \"cat\", \"tv\", \"dog-tv\", \"b\",\"2\"),\n",
    "                (\"simpsons   cat lady\", 2, \"frog\", \"table\",\"eagle-tv-plus\",\"1\",\"3\"),\n",
    "                (None, 3, \"eagle\", \"glass\", \"lion-pc\", \"c\",\"4\")\n",
    "            ])\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Columns\n",
    "### Spark\n",
    "* You can not create multiple columns at the same time\n",
    "* You need to use the lit function. lit???\n",
    "\n",
    "### Pandas\n",
    "* Similiar behavior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "|              words|num|animals|thing|  two strings|filter|num 2|new_col_1|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "|  I like     fish  |  1|    dog|housé|      cat-car|     a|    1|        1|\n",
      "|            zombies|  2|    cat|   tv|       dog-tv|     b|    2|        1|\n",
      "|simpsons   cat lady|  2|   frog|table|eagle-tv-plus|     1|    3|        1|\n",
      "|               null|  3|  eagle|glass|      lion-pc|     c|    4|        1|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.cols().create(\"new_col_1\", 1)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "|              words|num|animals|thing|  two strings|filter|num 2|new_col_1|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "|  I like     fish  |  1|    dog|housé|      cat-car|     a|    1|        1|\n",
      "|            zombies|  2|    cat|   tv|       dog-tv|     b|    2|        1|\n",
      "|simpsons   cat lady|  2|   frog|table|eagle-tv-plus|     1|    3|        1|\n",
      "|               null|  3|  eagle|glass|      lion-pc|     c|    4|        1|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "sf = df.cols().create([\n",
    "    (\"new_col_2\", 2.22),\n",
    "    (\"new_col_3\", lit(3)),\n",
    "    (\"new_col_4\", \"test\"),\n",
    "    (\"new_col_5\", df['num']*2)\n",
    "    ])\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select columns\n",
    "### Spark\n",
    "* You can not select columns by string and index at the same time\n",
    "\n",
    "### Pandas\n",
    "* You can not select columns by string and index at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+-----+\n",
      "|              words|num|animals|thing|\n",
      "+-------------------+---+-------+-----+\n",
      "|  I like     fish  |  1|    dog|housé|\n",
      "|            zombies|  2|    cat|   tv|\n",
      "|simpsons   cat lady|  2|   frog|table|\n",
      "|               null|  3|  eagle|glass|\n",
      "+-------------------+---+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = [\"words\", 1, \"animals\", 3]\n",
    "df.cols().select(columns).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---------+\n",
      "|num|num 2|new_col_1|\n",
      "+---+-----+---------+\n",
      "|  1|    1|        1|\n",
      "|  2|    2|        1|\n",
      "|  2|    3|        1|\n",
      "|  3|    4|        1|\n",
      "+---+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cols().select(regex = \"n.*\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename Column\n",
    "### Spark\n",
    "You can not rename multiple columns using Spark Vanilla API\n",
    "\n",
    "\n",
    "### Pandas\n",
    "* Almost the same behavior https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.rename.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+-------+-----+-------------+------+-----+---------+\n",
      "|              words|number|animals|thing|  two strings|filter|num 2|new_col_1|\n",
      "+-------------------+------+-------+-----+-------------+------+-----+---------+\n",
      "|  I like     fish  |     1|    dog|housé|      cat-car|     a|    1|        1|\n",
      "|            zombies|     2|    cat|   tv|       dog-tv|     b|    2|        1|\n",
      "|simpsons   cat lady|     2|   frog|table|eagle-tv-plus|     1|    3|        1|\n",
      "|               null|     3|  eagle|glass|      lion-pc|     c|    4|        1|\n",
      "+-------------------+------+-------+-----+-------------+------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cols().rename([('num','number')]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "|              words|num|animals|thing|  two strings|filter|num 2|new_col_1|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "|  I like     fish  |  1|    dog|housé|      cat-car|     a|    1|        1|\n",
      "|            zombies|  2|    cat|   tv|       dog-tv|     b|    2|        1|\n",
      "|simpsons   cat lady|  2|   frog|table|eagle-tv-plus|     1|    3|        1|\n",
      "|               null|  3|  eagle|glass|      lion-pc|     c|    4|        1|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cols().rename(func = str.lower).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "|              WORDS|NUM|ANIMALS|THING|  TWO STRINGS|FILTER|NUM 2|NEW_COL_1|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "|  I like     fish  |  1|    dog|housé|      cat-car|     a|    1|        1|\n",
      "|            zombies|  2|    cat|   tv|       dog-tv|     b|    2|        1|\n",
      "|simpsons   cat lady|  2|   frog|table|eagle-tv-plus|     1|    3|        1|\n",
      "|               null|  3|  eagle|glass|      lion-pc|     c|    4|        1|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cols().rename(func = str.upper).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cast a columns\n",
    "\n",
    "### Spark\n",
    "* Can not cast multiple columns\n",
    "\n",
    "### Pandas\n",
    "This is a opinionated way to handle column casting. \n",
    "One of the first thing that every data cleaning process need to acomplish is define a data dictionary.\n",
    "Because of that we prefer to create a tuple like this:\n",
    "\n",
    "df.cols().cast(\n",
    "[(\"words\",\"str\"),\n",
    "(\"num\",\"int\"),\n",
    "(\"animals\",\"float\"),\n",
    "(\"thing\",\"str\")]\n",
    ")\n",
    "\n",
    "instead of pandas\n",
    "\n",
    "pd.Series([1], dtype='int32')\n",
    "pd.Series([2], dtype='string')\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.astype.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[words: string, num: string, animals: string, thing: string, two strings: string, filter: string, num 2: int]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cols().cast([(\"num\", \"string\"),(\"num 2\", \"integer\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep columns\n",
    "### Spark\n",
    "* You can not remove multiple columns\n",
    "\n",
    "### Pandas\n",
    "* Handle in pandas with drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[words: string, num: string, animals: string, thing: string, two strings: string, filter: string, num 2: string]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df.withColumn(\"num\", col(\"num\").cast(StringType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|num|\n",
      "+---+\n",
      "|  1|\n",
      "|  2|\n",
      "|  2|\n",
      "|  3|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cols().keep(\"num\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move columns\n",
    "### Spark\n",
    "Do not exist in spark\n",
    "\n",
    "### Pandas\n",
    "Do not exist in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+-------------------+-------------+------+-----+---------+\n",
      "|num|animals|thing|              words|  two strings|filter|num 2|new_col_1|\n",
      "+---+-------+-----+-------------------+-------------+------+-----+---------+\n",
      "|  1|    dog|housé|  I like     fish  |      cat-car|     a|    1|        1|\n",
      "|  2|    cat|   tv|            zombies|       dog-tv|     b|    2|        1|\n",
      "|  2|   frog|table|simpsons   cat lady|eagle-tv-plus|     1|    3|        1|\n",
      "|  3|  eagle|glass|               null|      lion-pc|     c|    4|        1|\n",
      "+---+-------+-----+-------------------+-------------+------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cols().move(\"words\", \"thing\", \"after\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Columns\n",
    "### Spark\n",
    "You can not sort columns using Spark Vanilla API \n",
    "\n",
    "### Pandas\n",
    "Similar to pandas\n",
    "http://pandas.pydata.org/pandas-docs/version/0.19/generated/pandas.DataFrame.sort_values.html#pandas.DataFrame.sort_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------+---+-----+-----+-------------+-------------------+\n",
      "|animals|filter|new_col_1|num|num 2|thing|  two strings|              words|\n",
      "+-------+------+---------+---+-----+-----+-------------+-------------------+\n",
      "|    dog|     a|        1|  1|    1|housé|      cat-car|  I like     fish  |\n",
      "|    cat|     b|        1|  2|    2|   tv|       dog-tv|            zombies|\n",
      "|   frog|     1|        1|  2|    3|table|eagle-tv-plus|simpsons   cat lady|\n",
      "|  eagle|     c|        1|  3|    4|glass|      lion-pc|               null|\n",
      "+-------+------+---------+---+-----+-----+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cols().sort().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+-----+-----+---+---------+------+-------+\n",
      "|              words|  two strings|thing|num 2|num|new_col_1|filter|animals|\n",
      "+-------------------+-------------+-----+-----+---+---------+------+-------+\n",
      "|  I like     fish  |      cat-car|housé|    1|  1|        1|     a|    dog|\n",
      "|            zombies|       dog-tv|   tv|    2|  2|        1|     b|    cat|\n",
      "|simpsons   cat lady|eagle-tv-plus|table|    3|  2|        1|     1|   frog|\n",
      "|               null|      lion-pc|glass|    4|  3|        1|     c|  eagle|\n",
      "+-------------------+-------------+-----+-----+---+---------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cols().sort(reverse = True).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop columns\n",
    "### Spark \n",
    "* You can not delete multiple colums\n",
    "\n",
    "### Pandas\n",
    "* Almost the same as pandas\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-------------+------+-----+---------+\n",
      "|animals|thing|  two strings|filter|num 2|new_col_1|\n",
      "+-------+-----+-------------+------+-----+---------+\n",
      "|    dog|housé|      cat-car|     a|    1|        1|\n",
      "|    cat|   tv|       dog-tv|     b|    2|        1|\n",
      "|   frog|table|eagle-tv-plus|     1|    3|        1|\n",
      "|  eagle|glass|      lion-pc|     c|    4|        1|\n",
      "+-------+-----+-------------+------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df.cols().drop(\"num\")\n",
    "df2 = df.cols().drop([\"num\",\"words\"])\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining\n",
    "\n",
    "cols y rows functions are used to organize and encapsulate optimus' functionality apart of Apache Spark Dataframe API. This have a disadvantage at chaining time because we need to user invoke cols or rows in every step.\n",
    "\n",
    "At the same time it can be helpfull when you look at the code because every line is self explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+-----+---------+---------+------+-------+\n",
      "|  two strings|thing|num 2|new_col_2|new_col_1|filter|animals|\n",
      "+-------------+-----+-----+---------+---------+------+-------+\n",
      "|      cat-car|housé|    1|spongebob|        1|     a|    dog|\n",
      "|       dog-tv|   tv|    2|spongebob|        1|     b|    cat|\n",
      "|eagle-tv-plus|table|    3|spongebob|        1|     1|   frog|\n",
      "|      lion-pc|glass|    4|spongebob|        1|     c|  eagle|\n",
      "+-------------+-----+-----+---------+---------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df\\\n",
    "    .cols().rename([('num','number')])\\\n",
    "    .cols().drop([\"number\",\"words\"])\\\n",
    "    .withColumn(\"new_col_2\", lit(\"spongebob\"))\\\n",
    "    .cols().create(\"new_col_1\", 1)\\\n",
    "    .cols().sort(reverse= True)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Columns\n",
    "### Spark\n",
    "\n",
    "### Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+-----+-------------+------+-----+---------+-----+-----+-----+\n",
      "|              words|num|animals|thing|  two strings|filter|num 2|new_col_1|COL_0|COL_1|COL_2|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+-----+-----+-----+\n",
      "|  I like     fish  |  1|    dog|housé|      cat-car|     a|    1|        1|  cat|  car| null|\n",
      "|            zombies|  2|    cat|   tv|       dog-tv|     b|    2|        1|  dog|   tv| null|\n",
      "|simpsons   cat lady|  2|   frog|table|eagle-tv-plus|     1|    3|        1|eagle|   tv| plus|\n",
      "|               null|  3|  eagle|glass|      lion-pc|     c|    4|        1| lion|   pc| null|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cols().split(\"two strings\",\"-\", n=3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+-----+-------------+------+-----+---------+-----+\n",
      "|              words|num|animals|thing|  two strings|filter|num 2|new_col_1|COL_1|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+-----+\n",
      "|  I like     fish  |  1|    dog|housé|      cat-car|     a|    1|        1|  car|\n",
      "|            zombies|  2|    cat|   tv|       dog-tv|     b|    2|        1|   tv|\n",
      "|simpsons   cat lady|  2|   frog|table|eagle-tv-plus|     1|    3|        1|   tv|\n",
      "|               null|  3|  eagle|glass|      lion-pc|     c|    4|        1|   pc|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cols().split(\"two strings\",\"-\", get = 1).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute\n",
    "### Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+-----+-------------+------+-----+---------+-----+-----+\n",
      "|              words|num|animals|thing|  two strings|filter|num 2|new_col_1|out_a|out_B|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+-----+-----+\n",
      "|  I like     fish  |1.0|    dog|housé|      cat-car|     a|  1.0|        1|  1.0|  1.0|\n",
      "|            zombies|2.0|    cat|   tv|       dog-tv|     b|  2.0|        1|  2.0|  2.0|\n",
      "|simpsons   cat lady|2.0|   frog|table|eagle-tv-plus|     1|  3.0|        1|  2.0|  3.0|\n",
      "|               null|3.0|  eagle|glass|      lion-pc|     c|  4.0|        1|  3.0|  4.0|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cols().impute([\"num\",\"num 2\"], [\"out_a\",\"out_B\"], strategy=\"mean\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get columns by type\n",
    "### Spark\n",
    "\n",
    "### Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of optimus.optimus failed: Traceback (most recent call last):\n",
      "  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 369, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\importlib\\__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Pc1\\Documents\\Optimus\\optimus\\optimus.py\", line 5, in <module>\n",
      "    from optimus.spark import Spark\n",
      "ImportError: cannot import name 'Spark'\n",
      "]\n",
      "[autoreload of optimus.spark failed: Traceback (most recent call last):\n",
      "  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 369, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\importlib\\__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Pc1\\Documents\\Optimus\\optimus\\spark.py\", line 5, in <module>\n",
      "    from .ml import patch\n",
      "ImportError: cannot import name 'patch'\n",
      "]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'get_column_names_by_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-08722ee94997>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_column_names_by_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"string\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1181\u001b[0m             raise AttributeError(\n\u001b[1;32m-> 1182\u001b[1;33m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0m\u001b[0;32m   1183\u001b[0m         \u001b[0mjc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'get_column_names_by_type'"
     ]
    }
   ],
   "source": [
    "df.get_column_names_by_type(\"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas comparision\n",
    "Pandas vs Spark\n",
    "https://www.analyticsvidhya.com/blog/2016/10/spark-dataframe-and-operations/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
