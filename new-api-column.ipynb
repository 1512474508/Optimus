{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimus import Optimus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "             ____        __  _                     \n",
      "            / __ \\____  / /_(_)___ ___  __  _______\n",
      "           / / / / __ \\/ __/ / __ `__ \\/ / / / ___/\n",
      "          / /_/ / /_/ / /_/ / / / / / / /_/ (__  ) \n",
      "          \\____/ .___/\\__/_/_/ /_/ /_/\\__,_/____/  \n",
      "              /_/                                  \n",
      "              \n",
      "Just checking that all necessary environments vars are present...\n",
      "-----\n",
      "PYSPARK_PYTHON=python\n",
      "SPARK_HOME=C:\\opt\\spark\\spark-2.3.1-bin-hadoop2.7\n",
      "JAVA_HOME=C:\\java8\n",
      "-----\n",
      "Starting or getting SparkSession and SparkContext...\n",
      "Setting checkpoint folder ( local ). If you are in a cluster initialize optimus with master='your_ip' as param\n",
      "Deleting previous folder if exists...\n",
      "Creating the checkpoint directory...\n",
      "Optimus successfully imported. Have fun :).\n"
     ]
    }
   ],
   "source": [
    "# Create optimus\n",
    "op = Optimus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe\n",
    "### Spark\n",
    "\n",
    "This is ugly:\n",
    "\n",
    "```\n",
    "val someData = Seq(\n",
    "  Row(8, \"bat\"),\n",
    "  Row(64, \"mouse\"),\n",
    "  Row(-27, \"horse\")\n",
    ")\n",
    "\n",
    "val someSchema = List(\n",
    "  StructField(\"number\", IntegerType, true),\n",
    "  StructField(\"word\", StringType, true)\n",
    ")\n",
    "\n",
    "val someDF = spark.createDataFrame(\n",
    "  spark.sparkContext.parallelize(someData),\n",
    "  StructType(someSchema)\n",
    ")```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+-----+-------------+------+-----+\n",
      "|              words|num|animals|thing|  two strings|filter|num 2|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+\n",
      "|  I like     fish  |  1|    dog|housé|      cat-car|     a|    1|\n",
      "|            zombies|  2|    cat|   tv|       dog-tv|     b|    2|\n",
      "|simpsons   cat lady|  2|   frog|table|eagle-tv-plus|     1|    3|\n",
      "|               null|  3|  eagle|glass|      lion-pc|     c|    4|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, BooleanType, IntegerType, ArrayType\n",
    "\n",
    "df = op.create.df(\n",
    "            [\n",
    "                (\"words\", \"str\", True),\n",
    "                (\"num\", \"int\", True),\n",
    "                (\"animals\", \"str\", True),\n",
    "                (\"thing\", StringType(), True),\n",
    "                (\"two strings\", StringType(), True),\n",
    "                (\"filter\", StringType(), True),\n",
    "                (\"num 2\", \"string\", True)\n",
    "\n",
    "            ]\n",
    ",\n",
    "[\n",
    "                (\"  I like     fish  \", 1, \"dog\", \"housé\", \"cat-car\", \"a\",\"1\"),\n",
    "                (\"    zombies\", 2, \"cat\", \"tv\", \"dog-tv\", \"b\",\"2\"),\n",
    "                (\"simpsons   cat lady\", 2, \"frog\", \"table\",\"eagle-tv-plus\",\"1\",\"3\"),\n",
    "                (None, 3, \"eagle\", \"glass\", \"lion-pc\", \"c\",\"4\")\n",
    "            ])\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Columns\n",
    "### Spark\n",
    "* You can not create multiple columns at the same time\n",
    "* You need to use the lit function. lit???\n",
    "\n",
    "### Pandas\n",
    "* Assing function seems to do the job https://stackoverflow.com/questions/12555323/adding-new-column-to-existing-dataframe-in-python-pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "|              words|num|animals|thing|  two strings|filter|num 2|new_col_1|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "|  I like     fish  |  1|    dog|housé|      cat-car|     a|    1|        1|\n",
      "|            zombies|  2|    cat|   tv|       dog-tv|     b|    2|        1|\n",
      "|simpsons   cat lady|  2|   frog|table|eagle-tv-plus|     1|    3|        1|\n",
      "|               null|  3|  eagle|glass|      lion-pc|     c|    4|        1|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.cols().append(\"new_col_1\", 1)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+-----+-------------+------+-----+---------+---------+---------+---------+---------+\n",
      "|              words|num|animals|thing|  two strings|filter|num 2|new_col_1|new_col_2|new_col_3|new_col_4|new_col_5|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+---------+---------+---------+---------+\n",
      "|  I like     fish  |  1|    dog|housé|      cat-car|     a|    1|        1|     2.22|        3|     test|        2|\n",
      "|            zombies|  2|    cat|   tv|       dog-tv|     b|    2|        1|     2.22|        3|     test|        4|\n",
      "|simpsons   cat lady|  2|   frog|table|eagle-tv-plus|     1|    3|        1|     2.22|        3|     test|        4|\n",
      "|               null|  3|  eagle|glass|      lion-pc|     c|    4|        1|     2.22|        3|     test|        6|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+---------+---------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "df.cols().append([\n",
    "    (\"new_col_2\", 2.22),\n",
    "    (\"new_col_3\", lit(3)),\n",
    "    (\"new_col_4\", \"test\"),\n",
    "    (\"new_col_5\", df['num']*2)\n",
    "    ]).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select columns\n",
    "### Spark\n",
    "* You can not select columns by string and index at the same time\n",
    "\n",
    "### Pandas\n",
    "* You can not select columns by string and index at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['words', 'num', 'animals', 'thing', 'words']\n",
      "+-------------------+---+-------+-----+-------------------+\n",
      "|              words|num|animals|thing|              words|\n",
      "+-------------------+---+-------+-----+-------------------+\n",
      "|  I like     fish  |  1|    dog|housé|  I like     fish  |\n",
      "|            zombies|  2|    cat|   tv|            zombies|\n",
      "|simpsons   cat lady|  2|   frog|table|simpsons   cat lady|\n",
      "|               null|  3|  eagle|glass|               null|\n",
      "+-------------------+---+-------+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = [\"words\", 1, \"animals\", 3, 0]\n",
    "df.cols().filter(columns).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['num', 'num 2', 'new_col_1']\n",
      "+---+-----+---------+\n",
      "|num|num 2|new_col_1|\n",
      "+---+-----+---------+\n",
      "|  1|    1|        1|\n",
      "|  2|    2|        1|\n",
      "|  2|    3|        1|\n",
      "|  3|    4|        1|\n",
      "+---+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cols().filter(\"n.*\", regex = True).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename Column\n",
    "### Spark\n",
    "You can not rename multiple columns using Spark Vanilla API\n",
    "\n",
    "\n",
    "### Pandas\n",
    "* Almost the same behavior https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.rename.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+-------+-----+-------------+------+-----+---------+\n",
      "|              words|number|animals|thing|  two strings|filter|num 2|new_col_1|\n",
      "+-------------------+------+-------+-----+-------------+------+-----+---------+\n",
      "|  I like     fish  |     1|    dog|housé|      cat-car|     a|    1|        1|\n",
      "|            zombies|     2|    cat|   tv|       dog-tv|     b|    2|        1|\n",
      "|simpsons   cat lady|     2|   frog|table|eagle-tv-plus|     1|    3|        1|\n",
      "|               null|     3|  eagle|glass|      lion-pc|     c|    4|        1|\n",
      "+-------------------+------+-------+-----+-------------+------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cols().rename([('num','number')]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "|              words|num|animals|thing|  two strings|filter|num 2|new_col_1|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "|  I like     fish  |  1|    dog|housé|      cat-car|     a|    1|        1|\n",
      "|            zombies|  2|    cat|   tv|       dog-tv|     b|    2|        1|\n",
      "|simpsons   cat lady|  2|   frog|table|eagle-tv-plus|     1|    3|        1|\n",
      "|               null|  3|  eagle|glass|      lion-pc|     c|    4|        1|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cols().rename(func = str.lower).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "|              WORDS|NUM|ANIMALS|THING|  TWO STRINGS|FILTER|NUM 2|NEW_COL_1|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "|  I like     fish  |  1|    dog|housé|      cat-car|     a|    1|        1|\n",
      "|            zombies|  2|    cat|   tv|       dog-tv|     b|    2|        1|\n",
      "|simpsons   cat lady|  2|   frog|table|eagle-tv-plus|     1|    3|        1|\n",
      "|               null|  3|  eagle|glass|      lion-pc|     c|    4|        1|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cols().rename(func = str.upper).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cast a columns\n",
    "\n",
    "### Spark\n",
    "* Can not cast multiple columns\n",
    "\n",
    "### Pandas\n",
    "This is a opinionated way to handle column casting. \n",
    "One of the first thing that every data cleaning process need to acomplish is define a data dictionary.\n",
    "Because of that we prefer to create a tuple like this:\n",
    "\n",
    "df.cols().cast(\n",
    "[(\"words\",\"str\"),\n",
    "(\"num\",\"int\"),\n",
    "(\"animals\",\"float\"),\n",
    "(\"thing\",\"str\")]\n",
    ")\n",
    "\n",
    "instead of pandas\n",
    "\n",
    "pd.Series([1], dtype='int32')\n",
    "pd.Series([2], dtype='string')\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.astype.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['num', 'num 2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[words: string, num: string, animals: string, thing: string, two strings: string, filter: string, num 2: int, new_col_1: int]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cols().cast([(\"num\", \"string\"),(\"num 2\", \"integer\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep columns\n",
    "### Spark\n",
    "* You can not remove multiple columns\n",
    "\n",
    "### Pandas\n",
    "* Handle in pandas with drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[words: string, num: string, animals: string, thing: string, two strings: string, filter: string, num 2: string, new_col_1: int]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df.withColumn(\"num\", col(\"num\").cast(StringType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['num']\n",
      "+---+\n",
      "|num|\n",
      "+---+\n",
      "|  1|\n",
      "|  2|\n",
      "|  2|\n",
      "|  3|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cols().keep(\"num\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move columns\n",
    "### Spark\n",
    "Do not exist in spark\n",
    "\n",
    "### Pandas\n",
    "Do not exist in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['words']\n",
      "['thing']\n",
      "+---+-------+-----+-------------------+-------------+------+-----+---------+\n",
      "|num|animals|thing|              words|  two strings|filter|num 2|new_col_1|\n",
      "+---+-------+-----+-------------------+-------------+------+-----+---------+\n",
      "|  1|    dog|housé|  I like     fish  |      cat-car|     a|    1|        1|\n",
      "|  2|    cat|   tv|            zombies|       dog-tv|     b|    2|        1|\n",
      "|  2|   frog|table|simpsons   cat lady|eagle-tv-plus|     1|    3|        1|\n",
      "|  3|  eagle|glass|               null|      lion-pc|     c|    4|        1|\n",
      "+---+-------+-----+-------------------+-------------+------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cols().move(\"words\", \"thing\", \"after\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Columns\n",
    "### Spark\n",
    "You can not sort columns using Spark Vanilla API \n",
    "\n",
    "### Pandas\n",
    "Similar to pandas\n",
    "http://pandas.pydata.org/pandas-docs/version/0.19/generated/pandas.DataFrame.sort_values.html#pandas.DataFrame.sort_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------+---+-----+-----+-------------+-------------------+\n",
      "|animals|filter|new_col_1|num|num 2|thing|  two strings|              words|\n",
      "+-------+------+---------+---+-----+-----+-------------+-------------------+\n",
      "|    dog|     a|        1|  1|    1|housé|      cat-car|  I like     fish  |\n",
      "|    cat|     b|        1|  2|    2|   tv|       dog-tv|            zombies|\n",
      "|   frog|     1|        1|  2|    3|table|eagle-tv-plus|simpsons   cat lady|\n",
      "|  eagle|     c|        1|  3|    4|glass|      lion-pc|               null|\n",
      "+-------+------+---------+---+-----+-----+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cols().sort().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+-----+-----+---+---------+------+-------+\n",
      "|              words|  two strings|thing|num 2|num|new_col_1|filter|animals|\n",
      "+-------------------+-------------+-----+-----+---+---------+------+-------+\n",
      "|  I like     fish  |      cat-car|housé|    1|  1|        1|     a|    dog|\n",
      "|            zombies|       dog-tv|   tv|    2|  2|        1|     b|    cat|\n",
      "|simpsons   cat lady|eagle-tv-plus|table|    3|  2|        1|     1|   frog|\n",
      "|               null|      lion-pc|glass|    4|  3|        1|     c|  eagle|\n",
      "+-------------------+-------------+-----+-----+---+---------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cols().sort(reverse = True).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop columns\n",
    "### Spark \n",
    "* You can not delete multiple colums\n",
    "\n",
    "### Pandas\n",
    "* Almost the same as pandas\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['num']\n",
      "['num', 'words']\n",
      "+-------+-----+-------------+------+-----+---------+\n",
      "|animals|thing|  two strings|filter|num 2|new_col_1|\n",
      "+-------+-----+-------------+------+-----+---------+\n",
      "|    dog|housé|      cat-car|     a|    1|        1|\n",
      "|    cat|   tv|       dog-tv|     b|    2|        1|\n",
      "|   frog|table|eagle-tv-plus|     1|    3|        1|\n",
      "|  eagle|glass|      lion-pc|     c|    4|        1|\n",
      "+-------+-----+-------------+------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df.cols().drop(\"num\")\n",
    "df2 = df.cols().drop([\"num\",\"words\"])\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining\n",
    "\n",
    "cols y rows functions are used to organize and encapsulate optimus' functionality apart of Apache Spark Dataframe API. This have a disadvantage at chaining time because we need to user invoke cols or rows in every step.\n",
    "\n",
    "At the same time it can be helpfull when you look at the code because every line is self explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+-----+---------+---------+------+-------+\n",
      "|  two strings|thing|num 2|new_col_2|new_col_1|filter|animals|\n",
      "+-------------+-----+-----+---------+---------+------+-------+\n",
      "|      cat-car|housé|    1|spongebob|        1|     a|    dog|\n",
      "|       dog-tv|   tv|    2|spongebob|        1|     b|    cat|\n",
      "|eagle-tv-plus|table|    3|spongebob|        1|     1|   frog|\n",
      "|      lion-pc|glass|    4|spongebob|        1|     c|  eagle|\n",
      "+-------------+-----+-----+---------+---------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df\\\n",
    "    .cols().rename([('num','number')])\\\n",
    "    .cols().drop([\"number\",\"words\"])\\\n",
    "    .withColumn(\"new_col_2\", lit(\"spongebob\"))\\\n",
    "    .cols().append(\"new_col_1\", 1)\\\n",
    "    .cols().sort(reverse= True)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Columns\n",
    "### Spark\n",
    "\n",
    "### Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Error: get param must be an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-70c5ba853c70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"two strings\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Optimus\\optimus\\helpers\\decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Optimus\\optimus\\dataframe\\columns.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(column, mark, get, n)\u001b[0m\n\u001b[0;32m    505\u001b[0m         \u001b[0msplit_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmark\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Error: get param must be an integer\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Error: get param must be an integer\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Error: get param must be an integer"
     ]
    }
   ],
   "source": [
    "df.cols().split(\"two strings\",\"-\", n=3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+-----+-------------+------+-----+---------+-----+\n",
      "|              words|num|animals|thing|  two strings|filter|num 2|new_col_1|COL_1|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+-----+\n",
      "|  I like     fish  |  1|    dog|housé|      cat-car|     a|    1|        1|  car|\n",
      "|            zombies|  2|    cat|   tv|       dog-tv|     b|    2|        1|   tv|\n",
      "|simpsons   cat lady|  2|   frog|table|eagle-tv-plus|     1|    3|        1|   tv|\n",
      "|               null|  3|  eagle|glass|      lion-pc|     c|    4|        1|   pc|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cols().split(\"two strings\",\"-\", get = 1).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute\n",
    "### Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "|              words|num|animals|thing|  two strings|filter|num 2|new_col_1|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "|  I like     fish  |1.0|    dog|housé|      cat-car|     a|  1.0|        1|\n",
      "|            zombies|2.0|    cat|   tv|       dog-tv|     b|  2.0|        1|\n",
      "|simpsons   cat lady|2.0|   frog|table|eagle-tv-plus|     1|  3.0|        1|\n",
      "|               null|3.0|  eagle|glass|      lion-pc|     c|  4.0|        1|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 =df.cols().cast([(\"num\",\"double\"),(\"num 2\", \"double\")])\n",
    "\n",
    "df1.cols().impute([\"num\",\"num 2\"], [\"out_a\",\"out_B\"], strategy=\"mean\")\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get columns by type\n",
    "### Spark\n",
    "\n",
    "### Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "|num|new_col_1|\n",
      "+---+---------+\n",
      "|  1|        1|\n",
      "|  2|        1|\n",
      "|  2|        1|\n",
      "|  3|        1|\n",
      "+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cols().filter_by_type(\"int\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply custom function\n",
    "### Spark\n",
    "You need to declare a UDF Spark function\n",
    "\n",
    "### Pandas\n",
    "Almost the same behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "|              words|num|animals|thing|  two strings|filter|num 2|new_col_1|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "|  I like     fish  |  2|    dog|housé|      cat-car|     a|    2|        1|\n",
      "|            zombies|  3|    cat|   tv|       dog-tv|     b|    3|        1|\n",
      "|simpsons   cat lady|  3|   frog|table|eagle-tv-plus|     1|    4|        1|\n",
      "|               null|  4|  eagle|glass|      lion-pc|     c|    5|        1|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def func(val, attr):\n",
    "    return str(int(val) + 1 )\n",
    "\n",
    "df.cols().apply( [\"num\",\"num 2\"], func, \"udf\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "|              words|num|animals|thing|  two strings|filter|num 2|new_col_1|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "|  I like     fish  |  2|    dog|housé|      cat-car|     a|    2|        1|\n",
      "|            zombies|  2|    cat|   tv|       dog-tv|     b|    2|        1|\n",
      "|simpsons   cat lady|  2|   frog|table|eagle-tv-plus|     1|    2|        1|\n",
      "|               null|  2|  eagle|glass|      lion-pc|     c|    2|        1|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "def func(col_name, attr):\n",
    "    return F.when(F.col(col_name)>0 ,2)\n",
    "\n",
    "df.cols().apply( [\"num\",\"num 2\"], func).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "|              words|num|animals|thing|  two strings|filter|num 2|new_col_1|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "|  I like     fish  |  1|    DOG|housé|      CAT-CAR|     a|    1|        1|\n",
      "|            zombies|  2|    CAT|   tv|       DOG-TV|     b|    2|        1|\n",
      "|simpsons   cat lady|  2|   FROG|table|EAGLE-TV-PLUS|     1|    3|        1|\n",
      "|               null|  3|  EAGLE|glass|      LION-PC|     c|    4|        1|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "def func(col_name, attr):\n",
    "    return F.upper(F.col(col_name))\n",
    "\n",
    "df.cols().apply([\"two strings\",\"animals\"], func).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Nulls\n",
    "### Spark\n",
    "\n",
    "### Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_null = op.get_ss().createDataFrame(\n",
    "    [(1, 1, None), (1, 2, float(5)), (1, 3, np.nan), (1, 4, None), (1, 5, float(10)), (1, 6, float('nan')), (1, 6, float('nan'))],\n",
    "    ('session', \"timestamp1\", \"id2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id2': 5}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_null.cols().count_na(\"id2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'session': 0, 'timestamp1': 0, 'id2': 5}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_null.cols().count_na(\"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count uniques\n",
    "### Spark\n",
    "\n",
    "### Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'words': 4,\n",
       " 'num': 3,\n",
       " 'animals': 4,\n",
       " 'thing': 4,\n",
       " 'two strings': 4,\n",
       " 'filter': 4,\n",
       " 'num 2': 4,\n",
       " 'new_col_1': 1}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cols().count_uniques(\"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique\n",
    "### Spark\n",
    "An abstraction of distinct to be use in multiple columns at the same time\n",
    "\n",
    "### Pandas\n",
    "Similar behavior than pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "|              words|num|animals|thing|  two strings|filter|num 2|new_col_1|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "|  I like     fish  |  1|    dog|housé|      cat-car|     a|    1|        1|\n",
      "|            zombies|  2|    cat|   tv|       dog-tv|     b|    2|        1|\n",
      "|simpsons   cat lady|  2|   frog|table|eagle-tv-plus|     1|    3|        1|\n",
      "|               null|  3|  eagle|glass|      lion-pc|     c|    4|        1|\n",
      "+-------------------+---+-------+-----+-------------+------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distinct = op.create.df(\n",
    "            [\n",
    "                (\"words\", \"str\", True),\n",
    "                (\"num\", \"int\", True)\n",
    "            ],\n",
    "[\n",
    "                (\"  I like     fish  \", 1),\n",
    "                (\"    zombies\", 2),\n",
    "                (\"simpsons   cat lady\", 2),\n",
    "                (None, 3),\n",
    "                  (None, 0)\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|num|\n",
      "+---+\n",
      "|  1|\n",
      "|  3|\n",
      "|  2|\n",
      "|  0|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_distinct\\\n",
    "    .select(\"num\")\\\n",
    "    .cols().unique().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+\n",
      "|              words|num|\n",
      "+-------------------+---+\n",
      "|  I like     fish  |  1|\n",
      "|            zombies|  2|\n",
      "|simpsons   cat lady|  2|\n",
      "|               null|  3|\n",
      "|               null|  0|\n",
      "+-------------------+---+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'words': 0, 'num': 1}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zeros = df_distinct\n",
    "df_zeros.show()\n",
    "df_zeros.cols().count_zeros(\"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas comparision\n",
    "Pandas vs Spark\n",
    "https://www.analyticsvidhya.com/blog/2016/10/spark-dataframe-and-operations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
