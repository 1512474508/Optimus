# For pyspark and Ipython:
*.ipynb_checkpoints/
*.log

# Directory-based project format:
.idea/

# Optimus

examples/checkPointFolder

metastore_db
spark-warehouse
projectFilesBackup/tests.py

# Distribution / packaging
build/
dist/
.eggs/
*.egg-info/
__pycache__/

# Spark-Package release
*.zip

__pycache__
.cache
.coverage*
.DS_Store
.pytest_cache/
data.json
.pytest_cache/README.md
examples/new-api-jar-test\.ipynb
venv/

# Test
tests/test.csv/
tests/test.json/
tests/test.parquet/
*.test

examples/new-api-optimus-jars\.ipynb
readme/credentials\.py
readme/data/foo\.json/
readme/data/foo\.parquet/
readme/data/foo\.csv/

examples/test\.parquet/
examples/test\.csv/
examples/test\.json/
examples/temp


node_modules


*bumblebee\.ini
examples/many-columns\.csv

examples/many=columns\.parquet/

examples/many-columns.parquet/

examples/sandbox.ipynb

examples/dask-worker-space/

examples/data/noncomm_use_subset/

examples/corona.ipynb

examples/data/AllData.xlsx

examples/data/HIGGS.csv

examples/data/jurgen.csv

examples/data/linkedin.csv

examples/data/metadata.csv

examples/data/netflix_titles.csv

examples/data/noncomm_use_subset.tar.gz

examples/data/Performance_2000Q4.csv

examples/data/personal_finance769k.csv

examples/data/star0000-1.csv

examples/data/taa.csv

examples/data/titanic3-1.xlsx

examples/mydask.png

examples/scheduling/dask-worker-space/global.lock

examples/scheduling/dask-worker-space/purge.lock

examples/scheduling/dask-worker-space/worker-33tgzejo.dirlock

examples/scheduling/dask-worker-space/worker-nio9ggwa.dirlock

examples/scheduling/dask-worker-space/worker-srvk35sp.dirlock

examples/scheduling/dask-worker-space/worker-wafwk8v4.dirlock

examples/yellow_tripdata_2009-01.csv

examples/yellow_tripdata_2009-02.csv

tests/creator/dask-worker-space/global.lock

tests/creator/dask-worker-space/purge.lock

tests/creator/creator-dask.ipynb

tests/creator/creator-dask.py
