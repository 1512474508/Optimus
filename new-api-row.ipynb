{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimus import *\n",
    "\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, BooleanType, IntegerType, ArrayType\n",
    "\n",
    "sc = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "             ____        __  _                     \n",
      "            / __ \\____  / /_(_)___ ___  __  _______\n",
      "           / / / / __ \\/ __/ / __ `__ \\/ / / / ___/\n",
      "          / /_/ / /_/ / /_/ / / / / / / /_/ (__  ) \n",
      "          \\____/ .___/\\__/_/_/ /_/ /_/\\__,_/____/  \n",
      "              /_/                                  \n",
      "              \n",
      "Just checking that all necessary environments vars are present...\n",
      "-----\n",
      "PYSPARK_PYTHON=python\n",
      "SPARK_HOME=C:\\opt\\spark\\spark-2.3.1-bin-hadoop2.7\n",
      "JAVA_HOME=C:\\java8\n",
      "-----\n",
      "Starting or getting SparkSession and SparkContext...\n",
      "Setting checkpoint folder ( local ). If you are in a cluster initialize optimus with master='your_ip' as param\n",
      "Deleting previous folder if exists...\n",
      "Creating the checkpoint directory...\n",
      "Optimus successfully imported. Have fun :).\n"
     ]
    }
   ],
   "source": [
    "# Create optimus\n",
    "op = Optimus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe\n",
    "### Spark\n",
    "\n",
    "This is ugly:\n",
    "\n",
    "```\n",
    "val someData = Seq(\n",
    "  Row(8, \"bat\"),\n",
    "  Row(64, \"mouse\"),\n",
    "  Row(-27, \"horse\")\n",
    ")\n",
    "\n",
    "val someSchema = List(\n",
    "  StructField(\"number\", IntegerType, true),\n",
    "  StructField(\"word\", StringType, true)\n",
    ")\n",
    "\n",
    "val someDF = spark.createDataFrame(\n",
    "  spark.sparkContext.parallelize(someData),\n",
    "  StructType(someSchema)\n",
    ")```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+-----+------+------+\n",
      "|              words|num|animals|thing|second|filter|\n",
      "+-------------------+---+-------+-----+------+------+\n",
      "|  I like     fish  |  1|dog dog|housé|     5|     a|\n",
      "|            zombies|  2|    cat|   tv|     6|     b|\n",
      "|simpsons   cat lady|  2|   frog|table|     7|     1|\n",
      "|               null|  3|  eagle|glass|     8|     c|\n",
      "+-------------------+---+-------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = op.create.df([\n",
    "                (\"words\", \"str\", True),\n",
    "                (\"num\", \"int\", True),\n",
    "                (\"animals\", \"str\", True),\n",
    "                (\"thing\", StringType(), True),\n",
    "                (\"second\", \"int\", True),\n",
    "                (\"filter\", StringType(), True)\n",
    "            ],\n",
    "            [\n",
    "                (\"  I like     fish  \", 1, \"dog dog\", \"housé\", 5 , \"a\"),\n",
    "                (\"    zombies\", 2, \"cat\", \"tv\", 6, \"b\"),\n",
    "                (\"simpsons   cat lady\", 2, \"frog\", \"table\", 7, \"1\"),\n",
    "                (None, 3, \"eagle\", \"glass\", 8, \"c\")\n",
    "                \n",
    "            ])\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('words', 'string'),\n",
       " ('num', 'int'),\n",
       " ('animals', 'string'),\n",
       " ('thing', 'string'),\n",
       " ('second', 'int'),\n",
       " ('filter', 'string')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append row\n",
    "### Spark\n",
    "Not available in Spark. You need to create a dataframe and the union to append a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-----------------+---------------+------+----------------+\n",
      "|              words|num|          animals|          thing|second|          filter|\n",
      "+-------------------+---+-----------------+---------------+------+----------------+\n",
      "|  I like     fish  |  1|          dog dog|          housé|     5|               a|\n",
      "|            zombies|  2|              cat|             tv|     6|               b|\n",
      "|simpsons   cat lady|  2|             frog|          table|     7|               1|\n",
      "|               null|  3|            eagle|          glass|     8|               c|\n",
      "|     this is a word|  2|this is an animal|this is a thing|    64|this is a filter|\n",
      "+-------------------+---+-----------------+---------------+------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.rows().append([\"this is a word\",2, \"this is an animal\", \"this is a thing\", 64, \"this is a filter\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter by type\n",
    "### Spark \n",
    "Not available in Spark Vanilla.\n",
    "\n",
    "### Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid returnType: returnType should be DataType or str but is 200",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-2bd4c1a97425>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_by_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"filter\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"integer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Optimus\\optimus\\helpers\\decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Optimus\\optimus\\dataframe\\rows.py\u001b[0m in \u001b[0;36mfilter_by_type\u001b[1;34m(columns, type)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_col_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_data_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m             \u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_col_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_col_name\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# delete rows not matching the data type\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Optimus\\optimus\\helpers\\decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Optimus\\optimus\\dataframe\\columns.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(cols_attrs, func, func_type)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mattrs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m                 \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Optimus\\optimus\\dataframe\\columns.py\u001b[0m in \u001b[0;36mpandas_udf_func\u001b[1;34m(attr, func)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mpandas_udf_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpandas_udf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPandasUDFType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSCALAR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mudf_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\pyspark\\sql\\functions.py\u001b[0m in \u001b[0;36mpandas_udf\u001b[1;34m(f, returnType, functionType)\u001b[0m\n\u001b[0;32m   2304\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_create_udf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturnType\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalType\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2305\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2306\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_create_udf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturnType\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalType\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\pyspark\\sql\\udf.py\u001b[0m in \u001b[0;36m_create_udf\u001b[1;34m(f, returnType, evalType)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;31m# Set the name of the UserDefinedFunction object to be the name of function f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     udf_obj = UserDefinedFunction(\n\u001b[1;32m---> 71\u001b[1;33m         f, returnType=returnType, name=None, evalType=evalType, deterministic=True)\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mudf_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\pyspark\\sql\\udf.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, returnType, name, evalType, deterministic)\u001b[0m\n\u001b[0;32m     92\u001b[0m             raise TypeError(\n\u001b[0;32m     93\u001b[0m                 \u001b[1;34m\"Invalid returnType: returnType should be DataType or str \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m                 \"but is {}\".format(returnType))\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevalType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid returnType: returnType should be DataType or str but is 200"
     ]
    }
   ],
   "source": [
    "df.rows().filter_by_type(\"filter\", type = \"integer\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+-----+------+------+\n",
      "|              words|num|animals|thing|second|filter|\n",
      "+-------------------+---+-------+-----+------+------+\n",
      "|  I like     fish  |  2|dog dog|housé|     5|     a|\n",
      "|            zombies|  3|    cat|   tv|     6|     b|\n",
      "|simpsons   cat lady|  3|   frog|table|     7|     1|\n",
      "|               null|  4|  eagle|glass|     8|     c|\n",
      "+-------------------+---+-------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def func(value): \n",
    "    return str(int(value) + 1 )\n",
    "\n",
    "df.rows().apply('num', func).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply by type\n",
    "### Spark\n",
    "Not available in Spark Vanilla.\n",
    "\n",
    "### Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+-----+------+------+\n",
      "|              words|num|animals|thing|second|filter|\n",
      "+-------------------+---+-------+-----+------+------+\n",
      "|  I like     fish  |  2|dog dog|housé|     5|     a|\n",
      "|            zombies|  3|    cat|   tv|     6|     b|\n",
      "|simpsons   cat lady|  3|   frog|table|     7|     1|\n",
      "|               null|  4|  eagle|glass|     8|     c|\n",
      "+-------------------+---+-------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def func(value): \n",
    "    return str(int(value) + 1 )\n",
    "\n",
    "df.rows().apply_by_type([('num', 'integer', func)]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+-------+-----+------+------+\n",
      "|              words|num|animals|thing|second|filter|\n",
      "+-------------------+---+-------+-----+------+------+\n",
      "|  I like     fish  |  1|dog dog|  aaa|     5|     a|\n",
      "|            zombies|  2|    cat|  aaa|     6|     b|\n",
      "|simpsons   cat lady|  2|   frog|  aaa|     7|     d|\n",
      "|               null|  3|  eagle|  aaa|     8|     c|\n",
      "+-------------------+---+-------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.rows().apply_by_type([('filter', 'integer', \"d\"), ('thing', 'string', \"aaa\")]).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
